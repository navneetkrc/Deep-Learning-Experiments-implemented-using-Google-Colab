{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNqcJ4qG2DH944XDTPA+mSb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define labels\n",
        "LABEL_NLQ = \"NLQ\"\n",
        "LABEL_KS = \"KS\"\n",
        "LABELS = [LABEL_NLQ, LABEL_KS] # For mapping numerical labels back to strings\n",
        "\n",
        "# 1. Load and Prepare Data\n",
        "csv_file_path = 'ecommerce_queries.csv'\n",
        "try:\n",
        "    df = pd.read_csv(csv_file_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: CSV file not found at '{csv_file_path}'.\")\n",
        "    exit()\n",
        "\n",
        "# Map labels to numerical values\n",
        "label_map = {LABEL_KS: 0, LABEL_NLQ: 1}\n",
        "df['label_id'] = df['label'].map(label_map)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label_id']) # Stratify for balanced splits\n",
        "\n",
        "# 2. Load BERT Tokenizer and Model\n",
        "MODEL_NAME = \"bert-base-uncased\"  # You can try other BERT variants\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2) # Binary classification\n",
        "\n",
        "# Set device (GPU if available, else CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device);\n",
        "\n",
        "# 3. Create Dataset Class\n",
        "class EcommerceQueryDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len=128):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        query_text = str(self.data.iloc[index]['query'])\n",
        "        label = int(self.data.iloc[index]['label_id'])\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            query_text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt' # PyTorch tensors\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# 4. Create DataLoaders\n",
        "MAX_LEN = 128 # Maximum sequence length for BERT\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataset = EcommerceQueryDataset(train_df, tokenizer, max_len=MAX_LEN)\n",
        "val_dataset = EcommerceQueryDataset(val_df, tokenizer, max_len=MAX_LEN)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# 5. Optimizer and Scheduler\n",
        "EPOCHS = 3 # Adjust as needed\n",
        "LEARNING_RATE = 2e-5 # Typical learning rate for BERT fine-tuning\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "total_steps = len(train_dataloader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# 6. Training Loop\n",
        "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # Gradient clipping\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "    avg_train_loss = total_loss / len(dataloader)\n",
        "    return avg_train_loss\n",
        "\n",
        "def evaluate_epoch(model, dataloader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad(): # Disable gradient calculations during evaluation\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "            logits = outputs.logits\n",
        "            predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "            labels_cpu = labels.cpu().numpy()\n",
        "\n",
        "            all_predictions.extend(predictions)\n",
        "            all_labels.extend(labels_cpu)\n",
        "\n",
        "    avg_val_loss = total_loss / len(dataloader)\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    return avg_val_loss, accuracy, all_labels, all_predictions\n",
        "\n",
        "\n",
        "print(\"--- Training Started ---\")\n",
        "best_val_accuracy = 0\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss = train_epoch(model, train_dataloader, optimizer, scheduler, device)\n",
        "    val_loss, val_accuracy, val_labels, val_predictions = evaluate_epoch(model, val_dataloader, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}:\")\n",
        "    print(f\"  Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        # Save the best model (optional)\n",
        "        # model.save_pretrained(\"./best_ecommerce_query_classifier\")\n",
        "        print(\"  --- Best validation accuracy improved, model saved (optional) ---\")\n",
        "\n",
        "print(\"--- Training Finished ---\")\n",
        "print(f\"Best Validation Accuracy: {best_val_accuracy:.4f}\")\n",
        "\n",
        "# 8. Evaluation Metrics and Report on Validation Set\n",
        "print(\"\\n--- Validation Set Evaluation ---\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(val_labels, val_predictions, target_names=LABELS))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(val_labels, val_predictions)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=LABELS, yticklabels=LABELS)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix - Validation Set')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 9. Prediction Function (for new queries)\n",
        "def predict_query_label(query_text, model, tokenizer, device, max_len=MAX_LEN, label_list=LABELS):\n",
        "    model.eval() # Set model to evaluation mode\n",
        "    encoding = tokenizer.encode_plus(\n",
        "        query_text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_len,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt' # PyTorch tensors\n",
        "    )\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        probabilities = torch.softmax(logits, dim=-1) # Get probabilities\n",
        "        predicted_class_id = torch.argmax(probabilities, dim=-1).item() # Get class index\n",
        "\n",
        "    predicted_label = label_list[predicted_class_id] # Map index back to label string\n",
        "    return predicted_label, probabilities[0][predicted_class_id].item() # Return label and probability\n",
        "\n",
        "\n",
        "# --- Example Prediction ---\n",
        "example_queries = [\n",
        "    \"Where can I find cheap Samsung phones?\",\n",
        "    \"Samsung tv price drop\",\n",
        "    \"Tell me about the new galaxy Watch.\",\n",
        "    \"galaxy buds features\",\n",
        "    \"best noise cancelling headphones for work from home\"\n",
        "]\n",
        "\n",
        "print(\"\\n--- Example Predictions ---\")\n",
        "for query in example_queries:\n",
        "    predicted_label, probability = predict_query_label(query, model, tokenizer, device)\n",
        "    print(f\"Query: '{query}'\")\n",
        "    print(f\"Predicted Label: {predicted_label} (Probability: {probability:.4f})\")\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "id": "TRBgpdib9BTg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "15305954da06430da6c70ba67abdaa5d",
            "7d19aa06320a4d9aa1e29d40886c5a1c",
            "575def7645544223a374afff8dc90a1b",
            "09783fd7e78a4635a6509d2259cdfdcb",
            "c7f9dd4732e1415997cfd6c73b0fd34a"
          ]
        },
        "outputId": "be99713e-2293-406d-b1bd-582e4a4a17d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "15305954da06430da6c70ba67abdaa5d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7d19aa06320a4d9aa1e29d40886c5a1c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "575def7645544223a374afff8dc90a1b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "09783fd7e78a4635a6509d2259cdfdcb",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c7f9dd4732e1415997cfd6c73b0fd34a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training Started ---\n",
            "Epoch 1/3:\n",
            "  Train Loss: 0.3302, Val Loss: 0.1298, Val Accuracy: 0.9651\n",
            "  --- Best validation accuracy improved, model saved (optional) ---\n",
            "Epoch 2/3:\n",
            "  Train Loss: 0.0699, Val Loss: 0.0346, Val Accuracy: 0.9869\n",
            "  --- Best validation accuracy improved, model saved (optional) ---\n",
            "Epoch 3/3:\n",
            "  Train Loss: 0.0214, Val Loss: 0.0185, Val Accuracy: 1.0000\n",
            "  --- Best validation accuracy improved, model saved (optional) ---\n",
            "--- Training Finished ---\n",
            "Best Validation Accuracy: 1.0000\n",
            "\n",
            "--- Validation Set Evaluation ---\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         NLQ       1.00      1.00      1.00       157\n",
            "          KS       1.00      1.00      1.00        72\n",
            "\n",
            "    accuracy                           1.00       229\n",
            "   macro avg       1.00      1.00      1.00       229\n",
            "weighted avg       1.00      1.00      1.00       229\n",
            "\n",
            "\n",
            "Confusion Matrix:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Example Predictions ---\n",
            "Query: 'Where can I find cheap Samsung phones?'\n",
            "Predicted Label: KS (Probability: 0.9794)\n",
            "---\n",
            "Query: 'Samsung tv price drop'\n",
            "Predicted Label: NLQ (Probability: 0.9841)\n",
            "---\n",
            "Query: 'Tell me about the new galaxy Watch.'\n",
            "Predicted Label: KS (Probability: 0.8343)\n",
            "---\n",
            "Query: 'galaxy buds features'\n",
            "Predicted Label: NLQ (Probability: 0.9928)\n",
            "---\n",
            "Query: 'best noise cancelling headphones for work from home'\n",
            "Predicted Label: KS (Probability: 0.8430)\n",
            "---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define labels\n",
        "LABEL_NLQ = \"NLQ\"\n",
        "LABEL_KS = \"KS\"\n",
        "LABELS = [LABEL_NLQ, LABEL_KS] # For mapping numerical labels back to strings\n",
        "\n",
        "# 1. Load and Prepare Data\n",
        "csv_file_path = 'ecommerce_queries.csv'\n",
        "try:\n",
        "    df = pd.read_csv(csv_file_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: CSV file not found at '{csv_file_path}'.\")\n",
        "    exit()\n",
        "\n",
        "# Map labels to numerical values\n",
        "label_map = {LABEL_KS: 0, LABEL_NLQ: 1}\n",
        "df['label_id'] = df['label'].map(label_map)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label_id']) # Stratify for balanced splits\n",
        "\n",
        "# 2. Load BERT Tokenizer and Model\n",
        "MODEL_NAME = \"distilbert/distilbert-base-uncased\"  # You can try other BERT variants\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=2) # Binary classification\n",
        "\n",
        "# Set device (GPU if available, else CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device);\n",
        "\n",
        "# 3. Create Dataset Class\n",
        "class EcommerceQueryDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len=128):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        query_text = str(self.data.iloc[index]['query'])\n",
        "        label = int(self.data.iloc[index]['label_id'])\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            query_text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt' # PyTorch tensors\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# 4. Create DataLoaders\n",
        "MAX_LEN = 128 # Maximum sequence length for BERT\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "train_dataset = EcommerceQueryDataset(train_df, tokenizer, max_len=MAX_LEN)\n",
        "val_dataset = EcommerceQueryDataset(val_df, tokenizer, max_len=MAX_LEN)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# 5. Optimizer and Scheduler\n",
        "EPOCHS = 3 # Adjust as needed\n",
        "LEARNING_RATE = 2e-5 # Typical learning rate for BERT fine-tuning\n",
        "\n",
        "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "total_steps = len(train_dataloader) * EPOCHS\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "# 6. Training Loop\n",
        "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0) # Gradient clipping\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "    avg_train_loss = total_loss / len(dataloader)\n",
        "    return avg_train_loss\n",
        "\n",
        "def evaluate_epoch(model, dataloader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad(): # Disable gradient calculations during evaluation\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "            logits = outputs.logits\n",
        "            predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "            labels_cpu = labels.cpu().numpy()\n",
        "\n",
        "            all_predictions.extend(predictions)\n",
        "            all_labels.extend(labels_cpu)\n",
        "\n",
        "    avg_val_loss = total_loss / len(dataloader)\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    return avg_val_loss, accuracy, all_labels, all_predictions\n",
        "\n",
        "\n",
        "print(\"--- Training Started ---\")\n",
        "best_val_accuracy = 0\n",
        "for epoch in range(EPOCHS):\n",
        "    train_loss = train_epoch(model, train_dataloader, optimizer, scheduler, device)\n",
        "    val_loss, val_accuracy, val_labels, val_predictions = evaluate_epoch(model, val_dataloader, device)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{EPOCHS}:\")\n",
        "    print(f\"  Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "    if val_accuracy > best_val_accuracy:\n",
        "        best_val_accuracy = val_accuracy\n",
        "        # Save the best model (optional)\n",
        "        model.save_pretrained(\"./best_ecommerce_query_classifier\")\n",
        "        print(\"  --- Best validation accuracy improved, model saved (optional) ---\")\n",
        "\n",
        "print(\"--- Training Finished ---\")\n",
        "print(f\"Best Validation Accuracy: {best_val_accuracy:.4f}\")\n",
        "\n",
        "# 8. Evaluation Metrics and Report on Validation Set\n",
        "print(\"\\n--- Validation Set Evaluation ---\")\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(val_labels, val_predictions, target_names=LABELS))\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "cm = confusion_matrix(val_labels, val_predictions)\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=LABELS, yticklabels=LABELS)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix - Validation Set')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# 9. Prediction Function (for new queries)\n",
        "def predict_query_label(query_text, model, tokenizer, device, max_len=MAX_LEN, label_list=LABELS):\n",
        "    model.eval() # Set model to evaluation mode\n",
        "    encoding = tokenizer.encode_plus(\n",
        "        query_text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_len,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt' # PyTorch tensors\n",
        "    )\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        probabilities = torch.softmax(logits, dim=-1) # Get probabilities\n",
        "        predicted_class_id = torch.argmax(probabilities, dim=-1).item() # Get class index\n",
        "\n",
        "    predicted_label = label_list[predicted_class_id] # Map index back to label string\n",
        "    return predicted_label, probabilities[0][predicted_class_id].item() # Return label and probability\n",
        "\n",
        "\n",
        "# --- Example Prediction ---\n",
        "example_queries = [\n",
        "    \"Where can I find cheap Samsung phones?\",\n",
        "    \"Samsung tv price drop\",\n",
        "    \"Tell me about the new galaxy Watch.\",\n",
        "    \"galaxy buds features\",\n",
        "    \"best noise cancelling headphones for work from home\"\n",
        "]\n",
        "\n",
        "print(\"\\n--- Example Predictions ---\")\n",
        "for query in example_queries:\n",
        "    predicted_label, probability = predict_query_label(query, model, tokenizer, device)\n",
        "    print(f\"Query: '{query}'\")\n",
        "    print(f\"Predicted Label: {predicted_label} (Probability: {probability:.4f})\")\n",
        "    print(\"---\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K7xWc8JDasnn",
        "outputId": "52d6ca84-a8eb-4e43-b0ae-e1b940573c90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert/distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/optimization.py:591: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Training Started ---\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMVnfwvN3NPG"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define labels\n",
        "LABEL_NLQ = \"NLQ\"\n",
        "LABEL_KS = \"KS\"\n",
        "LABELS = [LABEL_NLQ, LABEL_KS]\n",
        "\n",
        "# Define models to compare (User can modify this list)\n",
        "MODELS_TO_COMPARE = [\"bert-base-uncased\", \"distilbert/distilbert-base-uncased\"]  # Default models\n",
        "\n",
        "# --- Data Loading and Preparation (same as before) ---\n",
        "csv_file_path = 'ecommerce_queries.csv'\n",
        "try:\n",
        "    df = pd.read_csv(csv_file_path)\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: CSV file not found at '{csv_file_path}'.\")\n",
        "    exit()\n",
        "\n",
        "label_map = {LABEL_KS: 0, LABEL_NLQ: 1}\n",
        "df['label_id'] = df['label'].map(label_map)\n",
        "\n",
        "train_df, val_df = train_test_split(df, test_size=0.2, random_state=42, stratify=df['label_id'])\n",
        "\n",
        "# --- Dataset Class (same as before) ---\n",
        "class EcommerceQueryDataset(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len=128):\n",
        "        self.data = dataframe\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        query_text = str(self.data.iloc[index]['query'])\n",
        "        label = int(self.data.iloc[index]['label_id'])\n",
        "        encoding = self.tokenizer.encode_plus(\n",
        "            query_text,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding='max_length',\n",
        "            truncation=True,\n",
        "            return_attention_mask=True,\n",
        "            return_tensors='pt'\n",
        "        )\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': torch.tensor(label, dtype=torch.long)\n",
        "        }\n",
        "\n",
        "# --- Training and Evaluation Functions (same as before) ---\n",
        "def train_epoch(model, dataloader, optimizer, scheduler, device):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch in dataloader:\n",
        "        input_ids = batch['input_ids'].to(device)\n",
        "        attention_mask = batch['attention_mask'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "    avg_train_loss = total_loss / len(dataloader)\n",
        "    return avg_train_loss\n",
        "\n",
        "def evaluate_epoch(model, dataloader, device):\n",
        "    model.eval()\n",
        "    total_loss = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    with torch.no_grad():\n",
        "        for batch in dataloader:\n",
        "            input_ids = batch['input_ids'].to(device)\n",
        "            attention_mask = batch['attention_mask'].to(device)\n",
        "            labels = batch['labels'].to(device)\n",
        "\n",
        "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
        "            loss = outputs.loss\n",
        "            total_loss += loss.item()\n",
        "            logits = outputs.logits\n",
        "            predictions = torch.argmax(logits, dim=-1).cpu().numpy()\n",
        "            labels_cpu = labels.cpu().numpy()\n",
        "\n",
        "            all_predictions.extend(predictions)\n",
        "            all_labels.extend(labels_cpu)\n",
        "\n",
        "    avg_val_loss = total_loss / len(dataloader)\n",
        "    accuracy = accuracy_score(all_labels, all_predictions)\n",
        "    return avg_val_loss, accuracy, all_labels, all_predictions\n",
        "\n",
        "# --- Prediction Function (same as before) ---\n",
        "def predict_query_label(query_text, model, tokenizer, device, max_len=128, label_list=LABELS):\n",
        "    model.eval()\n",
        "    encoding = tokenizer.encode_plus(\n",
        "        query_text,\n",
        "        add_special_tokens=True,\n",
        "        max_length=max_len,\n",
        "        padding='max_length',\n",
        "        truncation=True,\n",
        "        return_attention_mask=True,\n",
        "        return_tensors='pt'\n",
        "    )\n",
        "    input_ids = encoding['input_ids'].to(device)\n",
        "    attention_mask = encoding['attention_mask'].to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        logits = outputs.logits\n",
        "        probabilities = torch.softmax(logits, dim=-1)\n",
        "        predicted_class_id = torch.argmax(probabilities, dim=-1).item()\n",
        "\n",
        "    predicted_label = label_list[predicted_class_id]\n",
        "    return predicted_label, probabilities[0][predicted_class_id].item()\n",
        "\n",
        "# --- Model Comparison Loop ---\n",
        "model_performance_metrics = {} # Store performance metrics for each model\n",
        "\n",
        "for model_name in MODELS_TO_COMPARE:\n",
        "    print(f\"\\n--- Training and Evaluating Model: {model_name} ---\")\n",
        "\n",
        "    # 2. Load BERT Tokenizer and Model\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=2)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # 4. Create DataLoaders\n",
        "    MAX_LEN = 128\n",
        "    BATCH_SIZE = 32\n",
        "    train_dataset = EcommerceQueryDataset(train_df, tokenizer, max_len=MAX_LEN)\n",
        "    val_dataset = EcommerceQueryDataset(val_df, tokenizer, max_len=MAX_LEN)\n",
        "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "    val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    # 5. Optimizer and Scheduler\n",
        "    EPOCHS = 3\n",
        "    LEARNING_RATE = 2e-5\n",
        "    optimizer = AdamW(model.parameters(), lr=LEARNING_RATE)\n",
        "    total_steps = len(train_dataloader) * EPOCHS\n",
        "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n",
        "\n",
        "    # 6. Training and Evaluation Loop\n",
        "    best_val_accuracy = 0\n",
        "    for epoch in range(EPOCHS):\n",
        "        train_loss = train_epoch(model, train_dataloader, optimizer, scheduler, device)\n",
        "        val_loss, val_accuracy, val_labels, val_predictions = evaluate_epoch(model, val_dataloader, device)\n",
        "        print(f\"Epoch {epoch+1}/{EPOCHS}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "        if val_accuracy > best_val_accuracy:\n",
        "            best_val_accuracy = val_accuracy\n",
        "\n",
        "    # 8. Store Evaluation Metrics\n",
        "    print(f\"\\n--- {model_name} Validation Set Evaluation ---\")\n",
        "    report = classification_report(val_labels, val_predictions, target_names=LABELS, output_dict=True)\n",
        "    cm = confusion_matrix(val_labels, val_predictions)\n",
        "\n",
        "    model_performance_metrics[model_name] = {\n",
        "        'accuracy': best_val_accuracy, # Use best accuracy achieved during training\n",
        "        'precision_NLQ': report[LABEL_NLQ]['precision'],\n",
        "        'recall_NLQ': report[LABEL_NLQ]['recall'],\n",
        "        'f1-score_NLQ': report[LABEL_NLQ]['f1-score'],\n",
        "        'precision_KS': report[LABEL_KS]['precision'],\n",
        "        'recall_KS': report[LABEL_KS]['recall'],\n",
        "        'f1-score_KS': report[LABEL_KS]['f1-score'],\n",
        "        'confusion_matrix': cm\n",
        "    }\n",
        "\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(val_labels, val_predictions, target_names=LABELS))\n",
        "    print(\"\\nConfusion Matrix:\")\n",
        "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=LABELS, yticklabels=LABELS)\n",
        "    plt.xlabel('Predicted Label')\n",
        "    plt.ylabel('True Label')\n",
        "    plt.title(f'Confusion Matrix - {model_name} - Validation Set')\n",
        "    plt.show()\n",
        "\n",
        "# --- Performance Comparison Chart ---\n",
        "model_names = list(model_performance_metrics.keys())\n",
        "accuracy_scores = [model_performance_metrics[name]['accuracy'] for name in model_names]\n",
        "f1_scores_nlq = [model_performance_metrics[name]['f1-score_NLQ'] for name in model_names]\n",
        "f1_scores_ks = [model_performance_metrics[name]['f1-score_KS'] for name in model_names]\n",
        "\n",
        "x = range(len(model_names))\n",
        "width = 0.2\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.bar(x, accuracy_scores, width=width, label='Accuracy')\n",
        "plt.bar([i + width for i in x], f1_scores_nlq, width=width, label=f'F1-Score ({LABEL_NLQ})')\n",
        "plt.bar([i + 2*width for i in x], f1_scores_ks, width=width, label=f'F1-Score ({LABEL_KS})')\n",
        "\n",
        "plt.xticks([i + width for i in x], model_names, rotation=45, ha='right')\n",
        "plt.ylabel('Score')\n",
        "plt.xlabel('Model')\n",
        "plt.title('Performance Comparison of BERT Models')\n",
        "plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n--- Model Comparison Completed ---\")\n",
        "\n",
        "# --- Example Prediction using the first model in the list (you can change this) ---\n",
        "best_model_name = MODELS_TO_COMPARE[0] # Or choose based on comparison chart\n",
        "best_tokenizer = AutoTokenizer.from_pretrained(best_model_name)\n",
        "best_model = AutoModelForSequenceClassification.from_pretrained(best_model_name, num_labels=2).to(device)\n",
        "# Load the fine-tuned weights (if you saved them, otherwise, use the model after the last training loop)\n",
        "# best_model = AutoModelForSequenceClassification.from_pretrained(\"./best_ecommerce_query_classifier\").to(device) # Example if you saved\n",
        "\n",
        "example_queries = [\n",
        "    \"Where can I find cheap Samsung phones?\",\n",
        "    \"Samsung tv price drop\",\n",
        "    \"Tell me about the new galaxy Watch.\",\n",
        "    \"galaxy buds features\",\n",
        "    \"best noise cancelling headphones for work from home\"\n",
        "]\n",
        "\n",
        "print(f\"\\n--- Example Predictions using {best_model_name} ---\")\n",
        "for query in example_queries:\n",
        "    predicted_label, probability = predict_query_label(query, best_model, best_tokenizer, device)\n",
        "    print(f\"Query: '{query}'\")\n",
        "    print(f\"Predicted Label: {predicted_label} (Probability: {probability:.4f})\")\n",
        "    print(\"---\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AlxjZGDL8nvE"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}