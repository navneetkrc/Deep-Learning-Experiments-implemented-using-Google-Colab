{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/navneetkrc/Deep-Learning-Experiments-implemented-using-Google-Colab/blob/master/Text_Summarization_via_CLI_using_Ollama_with_Google_colab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ApKoENkyzqay"
      },
      "outputs": [],
      "source": [
        "# Cell 1 - Install Required Libraries:\n",
        "!pip install streamlit PyMuPDF4LLM pandas openpyxl pyngrok requests  # Added 'requests' for Ollama API calls\n",
        "\n",
        "# Install Ollama (using a convenient installation script)\n",
        "!curl -fsSL https://ollama.com/install.sh | sh\n",
        "\n",
        "# Install and setup ngrok (as in your original code)\n",
        "!curl -s https://ngrok-agent.s3.amazonaws.com/ngrok.asc | sudo tee /etc/apt/trusted.gpg.d/ngrok.asc >/dev/null && echo \"deb https://ngrok-agent.s3.amazonaws.com buster main\" | sudo tee /etc/apt/sources.list.d/ngrok.list && sudo apt update && sudo apt install ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hrNMdGgCUsf"
      },
      "outputs": [],
      "source": [
        "# Cell 2 - Import Libraries and Set Up Environment:\n",
        "import streamlit as st\n",
        "import fitz  # PyMuPDF4LLM\n",
        "import pandas as pd\n",
        "import os\n",
        "import time\n",
        "import requests  # For making requests to the Ollama API\n",
        "from google.colab import files\n",
        "\n",
        "from google.colab import userdata\n",
        "# Remove Groq API key setup\n",
        "# os.environ[\"GROQ_API_KEY\"] = userdata.get('groq_colab_key') #krch\n",
        "# os.environ[\"GROQ_API_KEY\"] = userdata.get('groq_604779')\n",
        "os.environ[\"NGROK_AUTH_TOKEN2\"] = userdata.get('NGROK_AUTH_TOKEN')\n",
        "\n",
        "# Get ngrok auth token from environment\n",
        "ngrok_token = userdata.get('NGROK_AUTH_TOKEN')\n",
        "!ngrok authtoken {ngrok_token}\n",
        "\n",
        "# Start Ollama in the background (replace 'model_one' and 'model_two' with your actual model names)\n",
        "!nohup ollama serve > ollama.log 2>&1 &\n",
        "!ollama pull gemma2  # Example - replace with your actual model names\n",
        "!ollama pull llama3.2 # Example - replace with your actual model names\n",
        "!ollama pull smallthinker # Example - replace with your actual model names\n",
        "!ollama pull qwen2.5 # Example - replace with your actual model names\n",
        "time.sleep(10) # Give Ollama time to start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6oQo-Klrxh7"
      },
      "outputs": [],
      "source": [
        "# Start Ollama in the background (replace 'model_one' and 'model_two' with your actual model names)\n",
        "!nohup ollama serve > ollama.log 2>&1 &\n",
        "# !ollama pull gemma2  # Example - replace with your actual model names\n",
        "# !ollama pull llama3.2 # Example - replace with your actual model names\n",
        "# !ollama pull smallthinker # Example - replace with your actual model names\n",
        "# !ollama pull qwen2.5 # Example - replace with your actual model names\n",
        "time.sleep(10) # Give Ollama time to start"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "954fRxgoB40Y"
      },
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install streamlit langchain-community"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nssgZf1uSpzX",
        "outputId": "572e1db8-4764-47e1-973f-e9be016ed6e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "##1 upload\n",
        "# %%writefile app.py\n",
        "# import streamlit as st\n",
        "# import pandas as pd\n",
        "# from langchain_community.llms import Ollama\n",
        "# import io\n",
        "# import requests\n",
        "\n",
        "# # Configure page settings\n",
        "# st.set_page_config(page_title=\"Multi-Model Text Summarizer\", page_icon=\"üìù\")\n",
        "\n",
        "# # Define constants\n",
        "# OLLAMA_BASE_URL = \"http://localhost:11434/\"\n",
        "# # MODELS = [\"gemma2\", \"llama3.2\", \"smallthinker\", \"qwen2.5\"]\n",
        "# MODELS = [\"gemma2\"]\n",
        "# def check_ollama_server():\n",
        "#     \"\"\"Check if Ollama server is running\"\"\"\n",
        "#     try:\n",
        "#         requests.get(f\"{OLLAMA_BASE_URL}\")\n",
        "#         return True\n",
        "#     except requests.exceptions.ConnectionError:\n",
        "#         return False\n",
        "\n",
        "# def verify_model(model_name):\n",
        "#     \"\"\"Verify if a model is available in Ollama\"\"\"\n",
        "#     try:\n",
        "#         response = requests.post(\n",
        "#             f\"{OLLAMA_BASE_URL}api/show\",\n",
        "#             json={\"name\": model_name}\n",
        "#         )\n",
        "#         return response.status_code == 200\n",
        "#     except requests.exceptions.ConnectionError:\n",
        "#         return False\n",
        "\n",
        "# def create_summary(content, model_name):\n",
        "#     \"\"\"\n",
        "#     Creates a summary using specified Ollama model\n",
        "#     Args:\n",
        "#         content (str): Text content to summarize\n",
        "#         model_name (str): Name of the model to use\n",
        "#     Returns:\n",
        "#         str: Summarized text\n",
        "#     \"\"\"\n",
        "#     try:\n",
        "#         ollama = Ollama(base_url=OLLAMA_BASE_URL, model=model_name)\n",
        "#         prompt = f\"\"\"\n",
        "#                 Summarize the following text:\n",
        "#                 {content.strip()}\n",
        "#                 Summarize the following Samsung support document in a bullet point list. The summary should be no more than 5 bullet points and capture the most essential information.\n",
        "#                 \"\"\"\n",
        "#         response = ollama.invoke(prompt)\n",
        "#         return response.strip()\n",
        "#     except Exception as e:\n",
        "#         return f\"Error with {model_name}: {str(e)}\"\n",
        "\n",
        "# def process_files(uploaded_files):\n",
        "#     \"\"\"\n",
        "#     Process multiple files and generate summaries using all models\n",
        "#     Args:\n",
        "#         uploaded_files: List of uploaded file objects\n",
        "#     Returns:\n",
        "#         pd.DataFrame: DataFrame containing summaries from all models\n",
        "#     \"\"\"\n",
        "#     results = []\n",
        "\n",
        "#     # Create progress bar\n",
        "#     progress_bar = st.progress(0)\n",
        "#     total_files = len(uploaded_files)\n",
        "\n",
        "#     for i, file in enumerate(uploaded_files):\n",
        "#         # Read file content\n",
        "#         content = file.read().decode('utf-8')\n",
        "\n",
        "#         # Get summaries from each model\n",
        "#         summaries = {model: create_summary(content, model) for model in MODELS}\n",
        "\n",
        "#         # Add to results\n",
        "#         result = {\"file_name\": file.name}\n",
        "#         result.update(summaries)\n",
        "#         results.append(result)\n",
        "\n",
        "#         # Update progress bar\n",
        "#         progress_bar.progress((i + 1) / total_files)\n",
        "\n",
        "#     return pd.DataFrame(results)\n",
        "\n",
        "# def main():\n",
        "#     st.title(\"üìù Multi-Model Text Summarizer\")\n",
        "#     st.markdown(\"Upload multiple text files to get summaries from different models.\")\n",
        "\n",
        "#     # Check server status\n",
        "#     server_status = check_ollama_server()\n",
        "#     if server_status:\n",
        "#         st.success(\"‚úÖ Ollama server is running\")\n",
        "#     else:\n",
        "#         st.error(\"‚ùå Ollama server is not running. Please start it with 'ollama serve'\")\n",
        "#         return\n",
        "\n",
        "#     # Check model status\n",
        "#     st.subheader(\"Model Status:\")\n",
        "#     models_available = True\n",
        "#     for model in MODELS:\n",
        "#         if verify_model(model):\n",
        "#             st.success(f\"‚úÖ {model} is available\")\n",
        "#         else:\n",
        "#             st.error(f\"‚ùå {model} is not available. Please pull it with 'ollama pull {model}'\")\n",
        "#             models_available = False\n",
        "\n",
        "#     if not models_available:\n",
        "#         st.warning(\"Please make sure all models are available before proceeding.\")\n",
        "#         return\n",
        "\n",
        "#     # File upload section\n",
        "#     uploaded_files = st.file_uploader(\n",
        "#         \"Upload text files\",\n",
        "#         type=['txt'],\n",
        "#         accept_multiple_files=True\n",
        "#     )\n",
        "\n",
        "#     if uploaded_files:\n",
        "#         # Display file names\n",
        "#         st.write(\"Uploaded files:\")\n",
        "#         for file in uploaded_files:\n",
        "#             st.write(f\"- {file.name}\")\n",
        "\n",
        "#         if st.button(\"Generate Summaries\"):\n",
        "#             with st.spinner(\"Processing files...\"):\n",
        "#                 # Process files and get DataFrame\n",
        "#                 df = process_files(uploaded_files)\n",
        "\n",
        "#                 # Save to Excel\n",
        "#                 excel_buffer = io.BytesIO()\n",
        "#                 df.to_excel(excel_buffer, index=False)\n",
        "#                 excel_buffer.seek(0)\n",
        "\n",
        "#                 # Display results\n",
        "#                 st.success(\"Processing complete!\")\n",
        "#                 st.subheader(\"Preview of Results:\")\n",
        "#                 st.dataframe(df)\n",
        "\n",
        "#                 # Add download button for Excel file\n",
        "#                 st.download_button(\n",
        "#                     label=\"Download Excel File\",\n",
        "#                     data=excel_buffer,\n",
        "#                     file_name=\"summaries.xlsx\",\n",
        "#                     mime=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n",
        "#                 )\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dfUOoMg_Bj7U",
        "outputId": "a0219e5f-c38f-4d48-d9f7-454a7fbb2ce9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing app.py\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# %%writefile app.py\n",
        "\n",
        "# import streamlit as st\n",
        "# from langchain_community.llms import Ollama\n",
        "\n",
        "# # Configure page settings\n",
        "# st.set_page_config(page_title=\"Text Summarizer\", page_icon=\"üìù\")\n",
        "\n",
        "# # Define constants\n",
        "# OLLAMA_BASE_URL = \"http://localhost:11434/\"\n",
        "# OLLAMA_MODEL_NAME = \"gemma2\"\n",
        "\n",
        "# def create_summary(content):\n",
        "#     \"\"\"\n",
        "#     Creates a summary using Ollama model\n",
        "#     Args:\n",
        "#         content (str): Text content to summarize\n",
        "#     Returns:\n",
        "#         str: Summarized text\n",
        "#     \"\"\"\n",
        "#     try:\n",
        "#         # Creating Ollama client\n",
        "#         ollama = Ollama(base_url=OLLAMA_BASE_URL, model=OLLAMA_MODEL_NAME)\n",
        "\n",
        "#         # Improved prompt design\n",
        "#         prompt = f\"\"\"\n",
        "#                 Summarize the following text:\n",
        "#                 {content.strip()}\n",
        "#                 Please provide a concise summary of the key points in the text.\n",
        "#                 \"\"\"\n",
        "\n",
        "#         # Making the API call\n",
        "#         response = ollama.invoke(prompt)\n",
        "#         return response.strip()\n",
        "#     except Exception as e:\n",
        "#         return f\"Error: An error occurred during summarization: {e}\"\n",
        "\n",
        "# def main():\n",
        "#     # Add title and description\n",
        "#     st.title(\"üìù Text Summarizer\")\n",
        "#     st.markdown(\"Upload a text file or enter text directly to get a summary.\")\n",
        "\n",
        "#     # Create tabs for different input methods\n",
        "#     tab1, tab2 = st.tabs([\"Enter Text\", \"Upload File\"])\n",
        "\n",
        "#     with tab1:\n",
        "#         # Text input\n",
        "#         text_input = st.text_area(\"Enter your text here:\", height=200)\n",
        "#         if st.button(\"Summarize Text\", key=\"summarize_text\"):\n",
        "#             if text_input:\n",
        "#                 with st.spinner(\"Generating summary...\"):\n",
        "#                     summary = create_summary(text_input)\n",
        "#                 st.subheader(\"Summary:\")\n",
        "#                 st.write(summary)\n",
        "#             else:\n",
        "#                 st.error(\"Please enter some text to summarize.\")\n",
        "\n",
        "#     with tab2:\n",
        "#         # File upload\n",
        "#         uploaded_file = st.file_uploader(\"Choose a text file\", type=['txt'])\n",
        "#         if uploaded_file is not None:\n",
        "#             content = uploaded_file.read().decode()\n",
        "#             st.text_area(\"File content:\", content, height=200)\n",
        "#             if st.button(\"Summarize File\", key=\"summarize_file\"):\n",
        "#                 with st.spinner(\"Generating summary...\"):\n",
        "#                     summary = create_summary(content)\n",
        "#                 st.subheader(\"Summary:\")\n",
        "#                 st.write(summary)\n",
        "\n",
        "# if __name__ == \"__main__\":\n",
        "#     main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgSeuRyUijho",
        "outputId": "eb5f2fe9-112b-444d-afcf-54fe7c28fbb3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "from langchain_community.llms import Ollama\n",
        "import pandas as pd\n",
        "import io\n",
        "import requests\n",
        "\n",
        "# Configure page settings\n",
        "st.set_page_config(page_title=\"Text Summarizer\", page_icon=\"üìù\")\n",
        "\n",
        "# Define constants\n",
        "OLLAMA_BASE_URL = \"http://localhost:11434/\"\n",
        "MODELS = [\"gemma2\", \"llama3.2\", \"smallthinker\", \"qwen2.5\"]\n",
        "# MODELS = [\"gemma:2b\", \"llama2\", \"smallthinker\", \"qwen:2\"]\n",
        "def check_ollama_server():\n",
        "    \"\"\"Check if Ollama server is running\"\"\"\n",
        "    try:\n",
        "        requests.get(f\"{OLLAMA_BASE_URL}\")\n",
        "        return True\n",
        "    except requests.exceptions.ConnectionError:\n",
        "        return False\n",
        "\n",
        "def verify_model(model_name):\n",
        "    \"\"\"Verify if a model is available in Ollama\"\"\"\n",
        "    try:\n",
        "        response = requests.post(\n",
        "            f\"{OLLAMA_BASE_URL}api/show\",\n",
        "            json={\"name\": model_name}\n",
        "        )\n",
        "        return response.status_code == 200\n",
        "    except requests.exceptions.ConnectionError:\n",
        "        return False\n",
        "\n",
        "def get_prompt(prompt_style, content):\n",
        "    \"\"\"Get the appropriate prompt template\"\"\"\n",
        "    prompts = {\n",
        "        \"Action-Focused\": {\n",
        "            \"name\": \"Action-Focused\",\n",
        "            \"template\": f\"\"\"\n",
        "            Summarize the following Samsung support document into a brief bullet point list outlining the key steps, solutions, or important information a customer needs to know quickly. Focus on actionable advice and problem resolution.\n",
        "            Text:\n",
        "            {content.strip()}\n",
        "            \"\"\"\n",
        "        },\n",
        "        \"Structured-Technical\": {\n",
        "            \"name\": \"Structured-Technical\",\n",
        "            \"template\": f\"\"\"\n",
        "            Summarize the following Samsung support document into a bullet point list covering these aspects:\n",
        "            ***Problem/Issue Addressed:** (What is this document about?)\n",
        "            ***Key Steps/Solutions:** (What are the main actions or solutions?)\n",
        "            ***Important Notes/Cautions:** (Are there any crucial warnings or things to remember?)\n",
        "            Text:\n",
        "            {content.strip()}\n",
        "            \"\"\"\n",
        "        },\n",
        "        \"Five-Point-Essential\": {\n",
        "            \"name\": \"Five-Point-Essential\",\n",
        "            \"template\": f\"\"\"\n",
        "            Summarize the following Samsung support document in a bullet point list. The summary should be no more than 5 bullet points and capture the most essential information.\n",
        "            Text:\n",
        "            {content.strip()}\n",
        "            \"\"\"\n",
        "        },\n",
        "        \"Quick-Resolution\": {\n",
        "            \"name\": \"Quick-Resolution\",\n",
        "            \"template\": f\"\"\"\n",
        "            Create an ultra-concise summary of this Samsung support document using this specific format:\n",
        "            ‚Ä¢ Issue: [One-line problem description]\n",
        "            ‚Ä¢ Fix: [Main solution in 1-2 steps]\n",
        "            ‚Ä¢ Note: [One critical warning or tip]\n",
        "\n",
        "            Keep each bullet to 10 words or less. Focus only on the most critical information that resolves the issue immediately.\n",
        "\n",
        "            Text:\n",
        "            {content.strip()}\n",
        "            \"\"\"\n",
        "        }\n",
        "    }\n",
        "    return prompts[prompt_style][\"template\"]\n",
        "\n",
        "def create_summary(content, model_name, prompt_style):\n",
        "    \"\"\"\n",
        "    Creates a summary using specified Ollama model and prompt style\n",
        "    \"\"\"\n",
        "    try:\n",
        "        ollama = Ollama(base_url=OLLAMA_BASE_URL, model=model_name)\n",
        "        prompt = get_prompt(prompt_style, content)\n",
        "        response = ollama.invoke(prompt)\n",
        "        return response.strip()\n",
        "    except Exception as e:\n",
        "        return f\"Error: An error occurred during summarization: {e}\"\n",
        "\n",
        "def process_files(uploaded_files, selected_model, prompt_style):\n",
        "    \"\"\"Process multiple files and return results as DataFrame\"\"\"\n",
        "    results = []\n",
        "\n",
        "    with st.spinner(\"Processing files...\"):\n",
        "        for file in uploaded_files:\n",
        "            content = file.read().decode()\n",
        "            summary = create_summary(content, selected_model, prompt_style)\n",
        "\n",
        "            results.append({\n",
        "                \"file_name\": file.name,\n",
        "                \"model_name\": selected_model,\n",
        "                \"prompt_style\": prompt_style,\n",
        "                \"summary\": summary\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(results)\n",
        "\n",
        "def main():\n",
        "    st.title(\"üìù Customizable Text Summarizer\")\n",
        "    st.markdown(\"Choose your model, prompt style, and upload files for summarization.\")\n",
        "\n",
        "    # Check Ollama server\n",
        "    if not check_ollama_server():\n",
        "        st.error(\"‚ùå Ollama server is not running. Please start it with 'ollama serve'\")\n",
        "        return\n",
        "\n",
        "    # Model selection\n",
        "    selected_model = st.selectbox(\n",
        "        \"Select Model\",\n",
        "        MODELS,\n",
        "        help=\"Choose the AI model for summarization\"\n",
        "    )\n",
        "\n",
        "    # Verify selected model\n",
        "    if not verify_model(selected_model):\n",
        "        st.error(f\"‚ùå {selected_model} is not available. Please pull it with 'ollama pull {selected_model}'\")\n",
        "        return\n",
        "\n",
        "    # Prompt style selection\n",
        "    prompt_style = st.selectbox(\n",
        "        \"Select Prompt Style\",\n",
        "        [\n",
        "            \"Action-Focused\",\n",
        "            \"Structured-Technical\",\n",
        "            \"Five-Point-Essential\",\n",
        "            \"Quick-Resolution\"\n",
        "        ],\n",
        "        help=\"\"\"\n",
        "        Action-Focused: Step-by-step solution guide\n",
        "        Structured-Technical: Comprehensive problem analysis\n",
        "        Five-Point-Essential: Limited key points\n",
        "        Quick-Resolution: Ultra-concise fix guide\n",
        "        \"\"\"\n",
        "    )\n",
        "\n",
        "    # Create tabs for different input methods\n",
        "    tab1, tab2 = st.tabs([\"Enter Text\", \"Upload Files\"])\n",
        "\n",
        "    with tab1:\n",
        "        text_input = st.text_area(\"Enter your text here:\", height=200)\n",
        "        if st.button(\"Summarize Text\", key=\"summarize_text\"):\n",
        "            if text_input:\n",
        "                with st.spinner(\"Generating summary...\"):\n",
        "                    summary = create_summary(text_input, selected_model, prompt_style)\n",
        "                st.subheader(\"Summary:\")\n",
        "                st.write(summary)\n",
        "            else:\n",
        "                st.error(\"Please enter some text to summarize.\")\n",
        "\n",
        "    with tab2:\n",
        "        uploaded_files = st.file_uploader(\n",
        "            \"Choose text files\",\n",
        "            type=['txt'],\n",
        "            accept_multiple_files=True\n",
        "        )\n",
        "\n",
        "        if uploaded_files:\n",
        "            if st.button(\"Process Files\", key=\"process_files\"):\n",
        "                # Process files and create DataFrame\n",
        "                df = process_files(uploaded_files, selected_model, prompt_style)\n",
        "\n",
        "                # Create Excel file\n",
        "                excel_buffer = io.BytesIO()\n",
        "                df.to_excel(excel_buffer, index=False)\n",
        "                excel_buffer.seek(0)\n",
        "\n",
        "                # Show results preview\n",
        "                st.subheader(\"Results Preview:\")\n",
        "                st.dataframe(df)\n",
        "\n",
        "                # Add download button\n",
        "                st.download_button(\n",
        "                    label=\"Download Excel Report\",\n",
        "                    data=excel_buffer,\n",
        "                    file_name=\"summaries.xlsx\",\n",
        "                    mime=\"application/vnd.openxmlformats-officedocument.spreadsheetml.sheet\"\n",
        "                )\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8rsOt7EBj9_",
        "outputId": "ade47b32-7abf-4a8d-ade9-7167fe098a3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error: could not connect to ollama app, is it running?\n"
          ]
        }
      ],
      "source": [
        "!ollama list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8-jgosrBs0S",
        "outputId": "43ba78b1-225d-4d4d-ec85-b8e98b642036"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Streamlit app URL: https://b73e-34-127-125-126.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "from pyngrok import ngrok\n",
        "import time\n",
        "\n",
        "# Kill any existing Streamlit processes\n",
        "!kill -9 $(pgrep streamlit) 2>/dev/null\n",
        "\n",
        "#Uncomment this in case of reruns\n",
        "# !nohup ollama serve > ollama.log 2>&1 &\n",
        "# time.sleep(10)\n",
        "\n",
        "# Start Streamlit\n",
        "!streamlit run app.py &>/content/logs.txt &\n",
        "time.sleep(5)\n",
        "\n",
        "# Create ngrok tunnel with correct configuration\n",
        "ngrok_tunnel = ngrok.connect(addr=\"8501\", proto=\"http\", bind_tls=True)\n",
        "print(f\"Streamlit app URL: {ngrok_tunnel.public_url}\")\n",
        "\n",
        "# Keep the tunnel open\n",
        "try:\n",
        "    while True:\n",
        "        time.sleep(1)\n",
        "except KeyboardInterrupt:\n",
        "    print(\"Closing ngrok tunnel...\")\n",
        "    ngrok.kill()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2Yb_YPLIBkAd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yZgJ_P1XBkCy"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Wfwy5sGJH0T",
        "outputId": "858535fb-b094-45e3-ad84-c1f8e5e2eccf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting summarizer.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile summarizer.py\n",
        "import argparse\n",
        "import json\n",
        "import requests\n",
        "from typing import Optional\n",
        "import sys\n",
        "\n",
        "class OllamaSummarizer:\n",
        "    def __init__(self, base_url: str = \"http://localhost:11434\", model: str = \"qwen2:0.5b\"):\n",
        "        \"\"\"Initialize the Ollama API client.\n",
        "\n",
        "        Args:\n",
        "            base_url (str): Base URL for Ollama API\n",
        "            model (str): Model name to use for summarization\n",
        "        \"\"\"\n",
        "        self.base_url = base_url.rstrip('/')\n",
        "        self.model = model\n",
        "        self.generate_url = f\"{self.base_url}/api/generate\"\n",
        "\n",
        "    def check_api_status(self) -> bool:\n",
        "        \"\"\"Check if Ollama API is accessible.\"\"\"\n",
        "        try:\n",
        "            response = requests.get(f\"{self.base_url}/api/tags\")\n",
        "            return response.status_code == 200\n",
        "        except requests.RequestException:\n",
        "            return False\n",
        "\n",
        "    def generate_summary(self, content: str) -> str:\n",
        "        \"\"\"Generate summary using Ollama API.\n",
        "\n",
        "        Args:\n",
        "            content (str): Text content to summarize\n",
        "\n",
        "        Returns:\n",
        "            str: Generated summary\n",
        "        \"\"\"\n",
        "        prompt = f\"\"\"\n",
        "        Summarize the following text:\n",
        "        {content.strip()}\n",
        "        Please provide a concise summary of the key points in the text.\n",
        "        \"\"\"\n",
        "\n",
        "        payload = {\n",
        "            \"model\": self.model,\n",
        "            \"prompt\": prompt,\n",
        "            \"stream\": False\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(self.generate_url, json=payload)\n",
        "            response.raise_for_status()\n",
        "            result = response.json()\n",
        "            return result.get('response', '').strip()\n",
        "        except requests.RequestException as e:\n",
        "            raise Exception(f\"API request failed: {str(e)}\")\n",
        "\n",
        "def read_file(file_path: str) -> str:\n",
        "    \"\"\"Read content from a file.\n",
        "\n",
        "    Args:\n",
        "        file_path (str): Path to the file\n",
        "\n",
        "    Returns:\n",
        "        str: File content\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            return file.read()\n",
        "    except IOError as e:\n",
        "        raise Exception(f\"Error reading file: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Text Summarizer using Ollama API\")\n",
        "\n",
        "    # Add arguments\n",
        "    input_group = parser.add_mutually_exclusive_group(required=True)\n",
        "    input_group.add_argument('-t', '--text', type=str, help=\"Text to summarize\")\n",
        "    input_group.add_argument('-f', '--file', type=str, help=\"Path to text file to summarize\")\n",
        "\n",
        "    parser.add_argument('--url', type=str,\n",
        "                       default=\"http://localhost:11434\",\n",
        "                       help=\"Ollama API base URL\")\n",
        "    parser.add_argument('--model', type=str,\n",
        "                       default=\"qwen2:0.5b\",\n",
        "                       help=\"Model name to use\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    try:\n",
        "        # Initialize summarizer\n",
        "        summarizer = OllamaSummarizer(base_url=args.url, model=args.model)\n",
        "\n",
        "        # Check API status\n",
        "        if not summarizer.check_api_status():\n",
        "            print(\"Error: Cannot connect to Ollama API. Make sure the server is running.\")\n",
        "            sys.exit(1)\n",
        "\n",
        "        # Get content from either text or file\n",
        "        content = read_file(args.file) if args.file else args.text\n",
        "\n",
        "        # Generate summary\n",
        "        print(\"Generating summary...\")\n",
        "        summary = summarizer.generate_summary(content)\n",
        "\n",
        "        print(\"\\nSummary:\")\n",
        "        print(\"-\" * 80)\n",
        "        print(summary)\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zjBdbQcTJH8U",
        "outputId": "b90bea1c-4aaf-44e4-a578-00c34a534eea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating summary...\n",
            "Error: API request failed: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n"
          ]
        }
      ],
      "source": [
        "!python summarizer.py -f /content/book.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HR64ef8nJH-1"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EZyNGv6aJIDw"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpUBXCXVLYFA"
      },
      "outputs": [],
      "source": [
        "# Running ollama in background in Google colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9W6Ftw8yLYC8",
        "outputId": "17e094fc-f34e-4401-ed17-cfc113531420"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing Ollama...\n",
            "Starting Ollama server...\n",
            "Ollama server started successfully!\n",
            "Pulling model gemma:2b...\n",
            "\n",
            "Available models:\n",
            "['gemma:2b', 'gemma2:latest', 'llama3.2:latest']\n",
            "\n",
            "Testing with prompt: What is machine learning?\n",
            "\n",
            "Response:\n",
            "Sure. Here's a definition of machine learning:\n",
            "\n",
            "**Machine learning** is a subfield of artificial intelligence (AI) that allows machines to learn from data without explicit programming. It involves algorithms that can analyze data, identify patterns, and make predictions or decisions based on those patterns.\n",
            "\n",
            "**Key concepts in machine learning:**\n",
            "\n",
            "* **Data:** Large amounts of data are the foundation of machine learning.\n",
            "* **Algorithms:** These are sets of rules or instructions that the algorithm follows to analyze and learn from data.\n",
            "* **Learning:** The algorithm is trained on data to learn the underlying patterns.\n",
            "* **Prediction:** Once trained, the algorithm can make predictions or decisions based on new data.\n",
            "* **Evaluation:** The accuracy and performance of the learned model are evaluated against real-world data.\n",
            "\n",
            "**Benefits of machine learning:**\n",
            "\n",
            "* **Increased efficiency:** Automates tasks and processes, reducing human effort.\n",
            "* **Improved accuracy:** Provides more accurate results than traditional methods.\n",
            "* **Enhanced decision-making:** Provides insights and predictions that can help better decisions.\n",
            "* **New possibilities:** Opens up new opportunities in various fields such as healthcare, finance, and marketing.\n",
            "\n",
            "**Examples of machine learning algorithms:**\n",
            "\n",
            "* **Supervised learning:** Training data is labeled by humans, such as image classification or language processing.\n",
            "* **Unsupervised learning:** No labeled data is used, and the algorithm discovers patterns on its own.\n",
            "* **Reinforcement learning:** An agent learns through trial and error by interacting with its environment.\n",
            "\n",
            "Machine learning is a rapidly evolving field with significant applications across various domains.\n"
          ]
        }
      ],
      "source": [
        "import subprocess\n",
        "import requests\n",
        "import time\n",
        "import json\n",
        "from typing import Optional\n",
        "\n",
        "class OllamaManager:\n",
        "    def __init__(self, base_url: str = \"http://localhost:11434\"):\n",
        "        self.base_url = base_url.rstrip('/')\n",
        "\n",
        "    def install_ollama(self) -> bool:\n",
        "        \"\"\"Install Ollama if not already installed\"\"\"\n",
        "        try:\n",
        "            print(\"Installing Ollama...\")\n",
        "            subprocess.run(\"curl https://ollama.ai/install.sh | sh\", shell=True, check=True)\n",
        "            return True\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"Error installing Ollama: {e}\")\n",
        "            return False\n",
        "\n",
        "    def start_server(self) -> bool:\n",
        "        \"\"\"Start Ollama server in background\"\"\"\n",
        "        try:\n",
        "            print(\"Starting Ollama server...\")\n",
        "            subprocess.Popen([\"ollama\", \"serve\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "            # Wait for server to start\n",
        "            for _ in range(5):  # Try for 5 seconds\n",
        "                time.sleep(1)\n",
        "                try:\n",
        "                    if self.check_server():\n",
        "                        print(\"Ollama server started successfully!\")\n",
        "                        return True\n",
        "                except:\n",
        "                    continue\n",
        "            return False\n",
        "        except Exception as e:\n",
        "            print(f\"Error starting server: {e}\")\n",
        "            return False\n",
        "\n",
        "    def check_server(self) -> bool:\n",
        "        \"\"\"Check if Ollama server is running\"\"\"\n",
        "        try:\n",
        "            response = requests.get(f\"{self.base_url}/api/tags\")\n",
        "            return response.status_code == 200\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    def pull_model(self, model_name: str) -> bool:\n",
        "        \"\"\"Pull a model from Ollama\"\"\"\n",
        "        try:\n",
        "            print(f\"Pulling model {model_name}...\")\n",
        "            subprocess.run([\"ollama\", \"pull\", model_name], check=True)\n",
        "            return True\n",
        "        except subprocess.CalledProcessError as e:\n",
        "            print(f\"Error pulling model: {e}\")\n",
        "            return False\n",
        "\n",
        "    def list_models(self) -> list:\n",
        "        \"\"\"List all available models\"\"\"\n",
        "        try:\n",
        "            response = requests.get(f\"{self.base_url}/api/tags\")\n",
        "            if response.status_code == 200:\n",
        "                return [model['name'] for model in response.json()['models']]\n",
        "            return []\n",
        "        except:\n",
        "            return []\n",
        "\n",
        "    def generate_response(self, model: str, prompt: str) -> Optional[str]:\n",
        "        \"\"\"Generate response using specified model\"\"\"\n",
        "        try:\n",
        "            payload = {\n",
        "                \"model\": model,\n",
        "                \"prompt\": prompt,\n",
        "                \"stream\": False\n",
        "            }\n",
        "            response = requests.post(f\"{self.base_url}/api/generate\", json=payload)\n",
        "            if response.status_code == 200:\n",
        "                return response.json().get('response', '')\n",
        "            return None\n",
        "        except Exception as e:\n",
        "            print(f\"Error generating response: {e}\")\n",
        "            return None\n",
        "\n",
        "# Example usage\n",
        "def main():\n",
        "    # Initialize Ollama manager\n",
        "    manager = OllamaManager()\n",
        "\n",
        "    # Install and start Ollama\n",
        "    if not manager.install_ollama():\n",
        "        print(\"Failed to install Ollama\")\n",
        "        return\n",
        "\n",
        "    if not manager.start_server():\n",
        "        print(\"Failed to start Ollama server\")\n",
        "        return\n",
        "\n",
        "    # Pull a model (e.g., gemma:2b)\n",
        "    model_name = \"gemma:2b\"\n",
        "    if not manager.pull_model(model_name):\n",
        "        print(f\"Failed to pull model {model_name}\")\n",
        "        return\n",
        "\n",
        "    # List available models\n",
        "    print(\"\\nAvailable models:\")\n",
        "    models = manager.list_models()\n",
        "    print(models)\n",
        "\n",
        "    # Test generation\n",
        "    prompt = \"What is machine learning?\"\n",
        "    print(f\"\\nTesting with prompt: {prompt}\")\n",
        "    response = manager.generate_response(model_name, prompt)\n",
        "    if response:\n",
        "        print(\"\\nResponse:\")\n",
        "        print(response)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xz2jqHUiLX_q",
        "outputId": "e6a31e04-9fb2-4d25-89ce-1964cad05685"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sure. Here's a simplified explanation of quantum computing:\n",
            "\n",
            "**What is it?**\n",
            "\n",
            "Quantum computing is a new type of computing that leverages the principles of quantum mechanics to solve problems that are too complex for classical computers.\n",
            "\n",
            "**Key principles:**\n",
            "\n",
            "* **Qubits**: Unlike classical bits that are either 0 or 1, qubits can exist in a state called superposition, where they are both 0 and 1 at the same time.\n",
            "* **Entanglement**: Qubits can also be entangled, meaning their states are correlated even when physically separated. This allows them to share information instantaneously.\n",
            "* **Quantum algorithms**: These are algorithms specifically designed to run on quantum computers, harnessing these principles to solve problems much faster than classical algorithms.\n",
            "\n",
            "**Benefits:**\n",
            "\n",
            "* **Drug discovery**: Quantum computing can significantly accelerate drug discovery by simulating molecular interactions and chemical reactions.\n",
            "* **Materials science**: It can help design new materials with desired properties, leading to advancements in various industries.\n",
            "* **Financial modeling**: Quantum computing can enhance financial modeling and risk assessment.\n",
            "* **Cryptography**: Quantum computers could break current encryption methods, requiring the development of new security solutions.\n",
            "\n",
            "**Challenges:**\n",
            "\n",
            "* **Building quantum computers**: Building large-scale quantum computers with many qubits is incredibly complex and expensive.\n",
            "* **Developing quantum algorithms**: Designing algorithms for specific problems is a challenging task.\n",
            "* **Maintaining quantum states**: Quantum information is sensitive to noise, requiring special techniques to maintain its integrity.\n",
            "\n",
            "**Overall**:\n",
            "\n",
            "Quantum computing is a rapidly evolving field with the potential to revolutionize various industries. While it's still early days, it holds immense promise for solving complex problems that are intractable for classical computers.\n",
            "\n",
            "I hope this explanation provides a basic understanding of quantum computing. If you have any further questions or want to delve deeper into specific aspects, please let me know.\n"
          ]
        }
      ],
      "source": [
        "# Create manager instance\n",
        "manager = OllamaManager()\n",
        "\n",
        "# Generate a response\n",
        "response = manager.generate_response(\"gemma2\", \"Explain quantum computing\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MZ7GckBkLX9N",
        "outputId": "f004270d-4c5f-4a3a-9570-f431b21d5de7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pulling model gemma2...\n",
            "['gemma2:latest', 'gemma:2b', 'llama3.2:latest']\n",
            "AI, or **Artificial Intelligence**, is a broad field of computer science focused on creating intelligent agents‚Äîsystems that can reason, learn, and act autonomously. \n",
            "\n",
            "Here's a breakdown:\n",
            "\n",
            "**Key Characteristics of AI:**\n",
            "\n",
            "* **Learning:** AI systems can analyze data and learn patterns, improving their performance over time.\n",
            "* **Reasoning:** They can use logic to solve problems and make decisions.\n",
            "* **Problem-solving:** AI can find solutions to complex issues by analyzing information and identifying optimal courses of action.\n",
            "* **Perception:** Some AI systems can interpret sensory input like images, sound, and text.\n",
            "* **Natural Language Understanding:**  AI can understand and respond to human language in a meaningful way.\n",
            "\n",
            "**Types of AI:**\n",
            "\n",
            "* **Narrow or Weak AI:** Designed for specific tasks, like playing chess or recommending products. (This is the most common type today)\n",
            "* **General or Strong AI:** Hypothetical AI with human-level intelligence capable of performing any intellectual task a person can.\n",
            "* **Super AI:**  Hypothetical AI that surpasses human intelligence in all aspects.\n",
            "\n",
            "**Applications of AI:**\n",
            "\n",
            "AI is already transforming various industries:\n",
            "\n",
            "* **Healthcare:** Diagnosis, drug discovery, personalized medicine\n",
            "* **Finance:** Fraud detection, risk assessment, algorithmic trading\n",
            "* **Transportation:** Self-driving cars, traffic optimization\n",
            "* **Customer Service:** Chatbots, virtual assistants\n",
            "* **Entertainment:** Recommender systems, content creation\n",
            "\n",
            "**Important Considerations:**\n",
            "\n",
            "* **Ethics:** AI raises ethical concerns about bias, job displacement, and accountability.\n",
            "* **Transparency:**  Understanding how AI systems make decisions is crucial for trust and fairness.\n",
            "* **Regulation:** Governments are working to develop regulations for responsible development and use of AI.\n",
            "\n",
            "\n",
            "Let me know if you have any more questions or want to explore a specific aspect of AI in more detail!\n"
          ]
        }
      ],
      "source": [
        "# Pull a different model\n",
        "manager.pull_model(\"gemma2\")\n",
        "\n",
        "# List available models\n",
        "print(manager.list_models())\n",
        "\n",
        "# Generate with new model\n",
        "response = manager.generate_response(\"gemma2\", \"What is AI?\")\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7jV99YQHMsvf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mNyZGfTVMstQ",
        "outputId": "3f1f01c1-ecc5-47bb-92f8-77efac154a00"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating summary...\n",
            "Error: API request failed: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-21-2a53eb0911b8>\", line 78, in generate_summary\n",
            "    response.raise_for_status()\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/requests/models.py\", line 1024, in raise_for_status\n",
            "    raise HTTPError(http_error_msg, response=self)\n",
            "requests.exceptions.HTTPError: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"<ipython-input-21-2a53eb0911b8>\", line 117, in main\n",
            "    summary = summarizer.generate_summary(content)\n",
            "  File \"<ipython-input-21-2a53eb0911b8>\", line 82, in generate_summary\n",
            "    raise Exception(f\"API request failed: {str(e)}\")\n",
            "Exception: API request failed: 404 Client Error: Not Found for url: http://localhost:11434/api/generate\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-21-2a53eb0911b8>\", line 129, in <cell line: 128>\n",
            "    main()\n",
            "  File \"<ipython-input-21-2a53eb0911b8>\", line 126, in main\n",
            "    sys.exit(1)\n",
            "SystemExit: 1\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "  File \"/usr/lib/python3.10/inspect.py\", line 1662, in getinnerframes\n",
            "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
            "AttributeError: 'tuple' object has no attribute 'tb_frame'\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-2a53eb0911b8>\u001b[0m in \u001b[0;36mgenerate_summary\u001b[0;34m(self, content)\u001b[0m\n\u001b[1;32m     77\u001b[0m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpayload\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_for_status\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mraise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhttp_error_msg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mHTTPError\u001b[0m: 404 Client Error: Not Found for url: http://localhost:11434/api/generate",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-2a53eb0911b8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Generating summary...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m         \u001b[0msummary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msummarizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-2a53eb0911b8>\u001b[0m in \u001b[0;36mgenerate_summary\u001b[0;34m(self, content)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRequestException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"API request failed: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: API request failed: 404 Client Error: Not Found for url: http://localhost:11434/api/generate",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-2a53eb0911b8>\u001b[0m in \u001b[0;36m<cell line: 128>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-21-2a53eb0911b8>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Error: {str(e)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mSystemExit\u001b[0m: 1",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2090\u001b[0m                     stb = ['An exception has occurred, use %tb to see '\n\u001b[1;32m   2091\u001b[0m                            'the full traceback.\\n']\n\u001b[0;32m-> 2092\u001b[0;31m                     stb.extend(self.InteractiveTB.get_exception_only(etype,\n\u001b[0m\u001b[1;32m   2093\u001b[0m                                                                      value))\n\u001b[1;32m   2094\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mget_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    752\u001b[0m         \u001b[0mvalue\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mexception\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \"\"\"\n\u001b[0;32m--> 754\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mListTB\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstructured_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mshow_exception_only\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    627\u001b[0m             \u001b[0mchained_exceptions_tb_offset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    628\u001b[0m             out_list = (\n\u001b[0;32m--> 629\u001b[0;31m                 self.structured_traceback(\n\u001b[0m\u001b[1;32m    630\u001b[0m                     \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0metb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchained_exc_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    631\u001b[0m                     chained_exceptions_tb_offset, context)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1122\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ],
      "source": [
        "import argparse\n",
        "import json\n",
        "import requests\n",
        "import sys\n",
        "import subprocess\n",
        "import time\n",
        "from typing import Optional\n",
        "\n",
        "class OllamaManager:\n",
        "    def __init__(self, base_url: str = \"http://localhost:11434\"):\n",
        "        self.base_url = base_url.rstrip('/')\n",
        "        self.ensure_server_running()\n",
        "\n",
        "    def ensure_server_running(self):\n",
        "        \"\"\"Ensure Ollama server is running, start if not\"\"\"\n",
        "        if not self.check_server():\n",
        "            self.start_server()\n",
        "\n",
        "    def check_server(self) -> bool:\n",
        "        \"\"\"Check if Ollama server is running\"\"\"\n",
        "        try:\n",
        "            response = requests.get(f\"{self.base_url}/api/tags\")\n",
        "            return response.status_code == 200\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    def start_server(self):\n",
        "        \"\"\"Start Ollama server\"\"\"\n",
        "        try:\n",
        "            print(\"Starting Ollama server...\")\n",
        "            subprocess.Popen([\"ollama\", \"serve\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "            # Wait for server to start\n",
        "            for _ in range(10):  # Try for 10 seconds\n",
        "                time.sleep(1)\n",
        "                if self.check_server():\n",
        "                    print(\"Ollama server started successfully!\")\n",
        "                    return\n",
        "            raise Exception(\"Server failed to start within timeout\")\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Error starting server: {e}\")\n",
        "\n",
        "class OllamaSummarizer:\n",
        "    def __init__(self, base_url: str = \"http://localhost:11434\", model: str = \"qwen2:0.5b\"):\n",
        "        \"\"\"Initialize the Ollama API client.\n",
        "\n",
        "        Args:\n",
        "            base_url (str): Base URL for Ollama API\n",
        "            model (str): Model name to use for summarization\n",
        "        \"\"\"\n",
        "        self.base_url = base_url.rstrip('/')\n",
        "        self.model = model\n",
        "        self.generate_url = f\"{self.base_url}/api/generate\"\n",
        "        self.manager = OllamaManager(base_url)\n",
        "\n",
        "    def generate_summary(self, content: str) -> str:\n",
        "        \"\"\"Generate summary using Ollama API.\n",
        "\n",
        "        Args:\n",
        "            content (str): Text content to summarize\n",
        "\n",
        "        Returns:\n",
        "            str: Generated summary\n",
        "        \"\"\"\n",
        "        prompt = f\"\"\"\n",
        "        Summarize the following text:\n",
        "        {content.strip()}\n",
        "        Please provide a concise summary of the key points in the text.\n",
        "        \"\"\"\n",
        "\n",
        "        payload = {\n",
        "            \"model\": self.model,\n",
        "            \"prompt\": prompt,\n",
        "            \"stream\": False\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(self.generate_url, json=payload)\n",
        "            response.raise_for_status()\n",
        "            result = response.json()\n",
        "            return result.get('response', '').strip()\n",
        "        except requests.RequestException as e:\n",
        "            raise Exception(f\"API request failed: {str(e)}\")\n",
        "\n",
        "def read_file(file_path: str) -> str:\n",
        "    \"\"\"Read content from a file.\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            return file.read()\n",
        "    except IOError as e:\n",
        "        raise Exception(f\"Error reading file: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Text Summarizer using Ollama API\")\n",
        "\n",
        "    input_group = parser.add_mutually_exclusive_group(required=True)\n",
        "    input_group.add_argument('-t', '--text', type=str, help=\"Text to summarize\")\n",
        "    input_group.add_argument('-f', '--file', type=str, help=\"Path to text file to summarize\")\n",
        "\n",
        "    parser.add_argument('--url', type=str,\n",
        "                       default=\"http://localhost:11434\",\n",
        "                       help=\"Ollama API base URL\")\n",
        "    parser.add_argument('--model', type=str,\n",
        "                       default=\"qwen2:0.5b\",\n",
        "                       help=\"Model name to use\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    try:\n",
        "        # Initialize summarizer (this will also ensure server is running)\n",
        "        summarizer = OllamaSummarizer(base_url=args.url, model=args.model)\n",
        "\n",
        "        # Get content from either text or file\n",
        "        content = read_file(args.file) if args.file else args.text\n",
        "\n",
        "        # Generate summary\n",
        "        print(\"Generating summary...\")\n",
        "        summary = summarizer.generate_summary(content)\n",
        "\n",
        "        print(\"\\nSummary:\")\n",
        "        print(\"-\" * 80)\n",
        "        print(summary)\n",
        "        print(\"-\" * 80)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mSEo0ny1MsqV",
        "outputId": "3bf90954-d24a-4e2e-9c2c-abfbe8a5b192"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 13269    0 13269    0     0  52432      0 --:--:-- --:--:-- --:--:-- 52654\n",
            ">>> Cleaning up old version at /usr/local/lib/ollama\n",
            ">>> Installing ollama to /usr/local\n",
            ">>> Downloading Linux amd64 bundle\n",
            "############################################################################################# 100.0%\n",
            ">>> Adding ollama user to video group...\n",
            ">>> Adding current user to ollama group...\n",
            ">>> Creating ollama systemd service...\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m systemd is not running\n",
            "\u001b[1m\u001b[31mWARNING:\u001b[m Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
            ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
            ">>> Install complete. Run \"ollama\" from the command line.\n"
          ]
        }
      ],
      "source": [
        "!curl https://ollama.ai/install.sh | sh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SKyzV6KlMsnr",
        "outputId": "a4e19f60-a7d1-4cf7-c5b9-9170fa120bd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25lpulling manifest ‚†ã \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ‚†ô \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ‚†π \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
            "pulling ff1d1fc78170... 100% ‚ñï‚ñè 5.4 GB                         \n",
            "pulling 109037bec39c... 100% ‚ñï‚ñè  136 B                         \n",
            "pulling 097a36493f71... 100% ‚ñï‚ñè 8.4 KB                         \n",
            "pulling 2490e7468436... 100% ‚ñï‚ñè   65 B                         \n",
            "pulling 10aa81da732e... 100% ‚ñï‚ñè  487 B                         \n",
            "verifying sha256 digest \n",
            "writing manifest \n",
            "success \u001b[?25h\n"
          ]
        }
      ],
      "source": [
        "!ollama pull gemma2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gTnjsHKeMxK-",
        "outputId": "bf6da08d-10bf-4021-f828-3980f0e6f589"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "NAME               ID              SIZE      MODIFIED               \n",
            "gemma2:latest      ff02c3702f32    5.4 GB    Less than a second ago    \n",
            "gemma:2b           b50d6c999e59    1.7 GB    About a minute ago        \n",
            "llama3.2:latest    a80c4f17acd5    2.0 GB    5 minutes ago             \n"
          ]
        }
      ],
      "source": [
        "!ollama list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ALwGjZ0lNugg",
        "outputId": "0cdb29ea-9eb7-43fd-bccd-946d0b02cdf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Writing multiprompt_summarizer.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile multiprompt_summarizer.py\n",
        "import argparse\n",
        "import json\n",
        "import requests\n",
        "import sys\n",
        "import subprocess\n",
        "import time\n",
        "from typing import Optional, List, Dict\n",
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class SummaryPrompt:\n",
        "    name: str\n",
        "    template: str\n",
        "\n",
        "class OllamaManager:\n",
        "    def __init__(self, base_url: str = \"http://localhost:11434\"):\n",
        "        self.base_url = base_url.rstrip('/')\n",
        "        self.ensure_server_running()\n",
        "\n",
        "    def ensure_server_running(self):\n",
        "        \"\"\"Ensure Ollama server is running, start if not\"\"\"\n",
        "        if not self.check_server():\n",
        "            self.start_server()\n",
        "\n",
        "    def check_server(self) -> bool:\n",
        "        \"\"\"Check if Ollama server is running\"\"\"\n",
        "        try:\n",
        "            response = requests.get(f\"{self.base_url}/api/tags\")\n",
        "            return response.status_code == 200\n",
        "        except:\n",
        "            return False\n",
        "\n",
        "    def start_server(self):\n",
        "        \"\"\"Start Ollama server\"\"\"\n",
        "        try:\n",
        "            print(\"Starting Ollama server...\")\n",
        "            subprocess.Popen([\"ollama\", \"serve\"], stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
        "            for _ in range(10):\n",
        "                time.sleep(1)\n",
        "                if self.check_server():\n",
        "                    print(\"Ollama server started successfully!\")\n",
        "                    return\n",
        "            raise Exception(\"Server failed to start within timeout\")\n",
        "        except Exception as e:\n",
        "            raise Exception(f\"Error starting server: {e}\")\n",
        "\n",
        "class MultiPromptSummarizer:\n",
        "    def __init__(self, base_url: str = \"http://localhost:11434\", model: str = \"qwen2:0.5b\"):\n",
        "        self.base_url = base_url.rstrip('/')\n",
        "        self.model = model\n",
        "        self.generate_url = f\"{self.base_url}/api/generate\"\n",
        "        self.manager = OllamaManager(base_url)\n",
        "\n",
        "        # Define the prompts\n",
        "        self.prompts = [\n",
        "            SummaryPrompt(\n",
        "                \"TLDR Style\",\n",
        "                \"\"\"Provide a concise, bullet-point \"TLDR\" summary of the following text. Highlight the most crucial information a reader should understand at a glance.\n",
        "                Text: {content}\"\"\"\n",
        "            ),\n",
        "            SummaryPrompt(\n",
        "                \"Structured Analysis\",\n",
        "                \"\"\"Summarize the following text into a bullet point list covering these aspects:\n",
        "                ***Problem/Issue Addressed:** (What is this document about?)\n",
        "                ***Key Steps/Solutions:** (What are the main actions or solutions?)\n",
        "                ***Important Notes/Cautions:** (Are there any crucial warnings or things to remember?)\n",
        "                Text: {content}\"\"\"\n",
        "            ),\n",
        "            SummaryPrompt(\n",
        "                \"Concise 5-Point\",\n",
        "                \"\"\"Summarize the following text in a bullet point list. The summary should be no more than 5 bullet points and capture the most essential information.\n",
        "                Text: {content}\"\"\"\n",
        "            ),\n",
        "            SummaryPrompt(\n",
        "                \"Comprehensive TLDR\",\n",
        "                \"\"\"Provide a comprehensive but clear summary of the following text, focusing on key points and actionable information. Format the response in clear sections.\n",
        "                Text: {content}\"\"\"\n",
        "            )\n",
        "        ]\n",
        "\n",
        "    def generate_summary(self, content: str, prompt_template: str) -> str:\n",
        "        \"\"\"Generate summary using Ollama API with specific prompt\"\"\"\n",
        "        payload = {\n",
        "            \"model\": self.model,\n",
        "            \"prompt\": prompt_template.format(content=content.strip()),\n",
        "            \"stream\": False\n",
        "        }\n",
        "\n",
        "        try:\n",
        "            response = requests.post(self.generate_url, json=payload)\n",
        "            response.raise_for_status()\n",
        "            result = response.json()\n",
        "            return result.get('response', '').strip()\n",
        "        except requests.RequestException as e:\n",
        "            raise Exception(f\"API request failed: {str(e)}\")\n",
        "\n",
        "    def summarize_all(self, content: str) -> Dict[str, str]:\n",
        "        \"\"\"Generate summaries using all prompts\"\"\"\n",
        "        summaries = {}\n",
        "        for prompt in self.prompts:\n",
        "            print(f\"\\nGenerating {prompt.name} summary...\")\n",
        "            summary = self.generate_summary(content, prompt.template)\n",
        "            summaries[prompt.name] = summary\n",
        "        return summaries\n",
        "\n",
        "def read_file(file_path: str) -> str:\n",
        "    \"\"\"Read content from a file.\"\"\"\n",
        "    try:\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            return file.read()\n",
        "    except IOError as e:\n",
        "        raise Exception(f\"Error reading file: {str(e)}\")\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Multi-Prompt Text Summarizer using Ollama API\")\n",
        "\n",
        "    input_group = parser.add_mutually_exclusive_group(required=True)\n",
        "    input_group.add_argument('-t', '--text', type=str, help=\"Text to summarize\")\n",
        "    input_group.add_argument('-f', '--file', type=str, help=\"Path to text file to summarize\")\n",
        "\n",
        "    parser.add_argument('--url', type=str,\n",
        "                       default=\"http://localhost:11434\",\n",
        "                       help=\"Ollama API base URL\")\n",
        "    parser.add_argument('--model', type=str,\n",
        "                       default=\"qwen2:0.5b\",\n",
        "                       help=\"Model name to use\")\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    try:\n",
        "        # Initialize summarizer\n",
        "        summarizer = MultiPromptSummarizer(base_url=args.url, model=args.model)\n",
        "\n",
        "        # Get content\n",
        "        content = read_file(args.file) if args.file else args.text\n",
        "\n",
        "        # Generate all summaries\n",
        "        print(\"\\nGenerating summaries using different approaches...\")\n",
        "        summaries = summarizer.summarize_all(content)\n",
        "\n",
        "        # Print results\n",
        "        print(\"\\n\" + \"=\"*80)\n",
        "        print(\"SUMMARY RESULTS\")\n",
        "        print(\"=\"*80)\n",
        "\n",
        "        for prompt_name, summary in summaries.items():\n",
        "            print(f\"\\n{prompt_name}\")\n",
        "            print(\"-\" * len(prompt_name))\n",
        "            print(summary)\n",
        "            print(\"\\n\" + \"=\"*80)\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error: {str(e)}\")\n",
        "        sys.exit(1)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZYJa4GvNQfD",
        "outputId": "629a3f6a-6d1b-41ee-9d77-054dfb5ad362"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating summary...\n",
            "\n",
            "Summary:\n",
            "--------------------------------------------------------------------------------\n",
            "This excerpt from \"Machine Learning Mastery\" delves into the final chapters of the book, highlighting the reader's accomplishments and providing guidance for further learning.\n",
            "\n",
            "**Key Points:**\n",
            "\n",
            "* **Congratulations!** The author commends the reader for completing the journey through machine learning algorithms, emphasizing their significant progress in understanding and implementing these concepts.\n",
            "* **Resources for Continued Learning:** The text offers recommendations for books, forums, Q&A websites, and direct contact with the author to facilitate ongoing learning and problem-solving in the field of machine learning.\n",
            "* **Looking Ahead:**  The book concludes by encouraging readers to continue exploring and mastering machine learning algorithms, assuring them that this is just the beginning of their journey.\n",
            "\n",
            "Overall, these final chapters serve as a celebration of the reader's achievements and a roadmap for continued growth in the exciting world of machine learning.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "!python summarizer.py -f /content/book.txt --model gemma2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1T0ZmnHPp4J",
        "outputId": "70727868-59d0-4c88-a793-fa49e529dffe"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating summary...\n",
            "\n",
            "Summary:\n",
            "--------------------------------------------------------------------------------\n",
            "This guide outlines troubleshooting steps for Samsung microwaves that aren't heating properly. \n",
            "\n",
            "**Start by:**\n",
            "\n",
            "* **Checking the power supply:** Ensure it's plugged into a working outlet and the cord isn't damaged.\n",
            "* **Inspecting the door seal:** Make sure it's clean, intact, and the door is fully closed.\n",
            "\n",
            "**Then try:**\n",
            "\n",
            "* **Testing the cooking mode:** Heat a cup of water for 1-2 minutes on high power. If it doesn't heat, there might be an issue with internal components.\n",
            "* **Resetting the microwave:** Unplug it for 30 seconds, then plug it back in and restart.\n",
            "\n",
            "**If these steps don't work, contact Samsung Support for further assistance.**  Provide your microwave's model and serial number.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "!python summarizer.py -f /content/samsung_microwave_support.txt --model gemma2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UgGsEI1dPp7U",
        "outputId": "848b31f9-b14b-46b2-e500-18be28d7f67c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating summary...\n",
            "\n",
            "Summary:\n",
            "--------------------------------------------------------------------------------\n",
            "This guide provides troubleshooting steps for cooling issues in Samsung refrigerators.  \n",
            "\n",
            "**Steps to take:**\n",
            "\n",
            "* **Check temperature settings:** Make sure both the fridge and freezer are set to the recommended temperatures (3¬∞C/ -18¬∞C).\n",
            "* **Inspect door seals:** Ensure they are clean, undamaged, and creating a tight seal. \n",
            "* **Clear ventilation:** Remove any food blocking air vents inside the refrigerator.\n",
            "* **Clean coils:** Use a vacuum or brush to clean the condenser coils located at the back or bottom of the fridge.\n",
            "* **Power cycle:** Unplug the refrigerator for 5 minutes, then plug it back in.\n",
            "\n",
            "If these steps don't resolve the issue, contact Samsung Support or schedule a repair.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "!python summarizer.py -f /content/samsung_refrigerator_support.txt --model gemma2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nnp9ySxePp44",
        "outputId": "17b45742-5620-4752-887c-f29457e463e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating summary...\n",
            "\n",
            "Summary:\n",
            "--------------------------------------------------------------------------------\n",
            "This guide outlines how to resolve battery drain issues on Samsung Galaxy smartphones. \n",
            "\n",
            "**Key tips include:** closing unused apps, optimizing settings (brightness, Bluetooth, GPS), enabling Battery Saver mode, checking app usage and uninstalling power-hungry ones, ensuring software updates are installed, and considering a battery replacement if the problem persists after two years.\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "!python summarizer.py -f /content/samsung_mobile_support.txt --model gemma2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTMqafNDSQoe",
        "outputId": "852d33f8-2827-4bb2-9b33-f5b151df96d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generating summaries using different approaches...\n",
            "\n",
            "Generating TLDR Style summary...\n",
            "\n",
            "Generating Structured Analysis summary...\n",
            "\n",
            "Generating Concise 5-Point summary...\n",
            "\n",
            "Generating Comprehensive TLDR summary...\n",
            "\n",
            "================================================================================\n",
            "SUMMARY RESULTS\n",
            "================================================================================\n",
            "\n",
            "TLDR Style\n",
            "----------\n",
            "The text you provided is a sample chapter from a book about machine learning algorithms. It outlines the journey of learning these algorithms and provides resources for further exploration.\n",
            "\n",
            "Here's a breakdown of what the text covers:\n",
            "\n",
            "* **Introduction:** The author congratulates the reader on completing the book and emphasizes the significant progress they've made in understanding machine learning algorithms.\n",
            "* **Summary of Learning Journey:**  The text highlights key milestones achieved during the learning process, including grasping fundamental concepts, implementing various algorithms (linear regression, logistic regression, decision trees, support vector machines, etc.), and exploring ensemble methods like bagging and boosting.\n",
            "* **Further Exploration Resources:** The author recommends several books, online forums, and Q&A websites as valuable resources for continuing the machine learning journey.\n",
            "\n",
            "* **Contact Information:** The author provides their email address for any questions or feedback.\n",
            "\n",
            "**Overall, this excerpt serves as a concluding chapter that celebrates the reader's accomplishments and guides them towards continued learning in the field of machine learning.** \n",
            "\n",
            "\n",
            "Let me know if you have any other questions about machine learning or need further clarification on specific concepts.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Structured Analysis\n",
            "-------------------\n",
            "The provided text is a summary and conclusion to a machine learning book.  It outlines the reader's journey through the book, highlights key concepts learned, and points to further resources for continued learning. \n",
            "\n",
            "Here are some of the key takeaways:\n",
            "\n",
            "* **The book covers a broad range of machine learning algorithms**: From linear regression and logistic regression to decision trees, support vector machines, bagging, and boosting.\n",
            "* **Emphasis on understanding, not just implementation**: The book encourages readers to deeply understand how algorithms work by implementing them from scratch in a spreadsheet. This promotes a stronger grasp of the underlying principles.\n",
            "* **Resources for further learning**: The book provides recommendations for books, online forums, and Q&A websites where readers can continue their machine learning journey.\n",
            "* **Contact information**: The author encourages readers to reach out with any questions or feedback.\n",
            "\n",
            "Overall, this text serves as a valuable concluding chapter, summarizing the accomplishments of the reader and guiding them towards continued exploration in the field of machine learning. \n",
            "\n",
            "\n",
            "Let me know if you have any other questions about this book summary or anything else!\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Concise 5-Point\n",
            "---------------\n",
            "This text provides a comprehensive summary of the Machine Learning Mastery book,  covering key concepts, algorithms implemented from scratch in a spreadsheet, and resources for further learning.\n",
            "\n",
            "**Here are some key takeaways:**\n",
            "\n",
            "* **Journey of Learning:** The book guides readers through a structured learning path, starting with fundamental machine learning principles and progressing to implementing various algorithms like linear regression, logistic regression, decision trees, support vector machines, bagging, and boosting.\n",
            "* **Hands-on Implementation:** A major strength is the emphasis on practical implementation using spreadsheets. This forces a deeper understanding of how algorithms work.\n",
            "* **Algorithm Coverage:** The book covers a wide range of both parametric and nonparametric algorithms, providing a well-rounded introduction to machine learning.\n",
            "* **Further Learning Resources:**  The concluding chapters offer valuable recommendations for books, forums, and Q&A sites to continue the learning journey beyond the book's scope.\n",
            "\n",
            "\n",
            "Let me know if you have any specific questions about the book's content or want more details on a particular algorithm discussed.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Comprehensive TLDR\n",
            "------------------\n",
            "The text you provided appears to be the conclusion and getting more help section of a book about machine learning algorithms. It's very informative and well-structured!  \n",
            "\n",
            "Here's a breakdown of what it covers:\n",
            "\n",
            "**Chapter 32: How Far You Have Come:**\n",
            "\n",
            "* **Acknowledgement:** Acknowledges the reader's journey in learning machine learning algorithms.\n",
            "* **Summary:** Briefly summarizes the key steps the reader has taken, from understanding basic concepts to implementing various algorithms.\n",
            "* **Encouragement:**  Motivates the reader to continue their learning and exploration of machine learning.\n",
            "\n",
            "**Chapter 33: Getting More Help:**\n",
            "\n",
            "* **Machine Learning Books:** Recommends several books for further learning, categorizing them by focus (statistical perspective, breadth vs. depth). Provides links to purchase these books on Amazon.\n",
            "* **Forums and Q&A Websites:** Lists popular platforms like Stack Overflow, Cross Validated, and Reddit's r/machinelearning as valuable resources for getting specific answers and engaging with the community.\n",
            "* **Contacting the Author:** Encourages readers to reach out directly if they have any questions or need assistance.\n",
            "\n",
            "**Errata:**\n",
            "\n",
            "* A section dedicated to listing changes made between different revisions of the book, ensuring accuracy and up-to-dateness.\n",
            "\n",
            "\n",
            "Let me know if you'd like me to elaborate on any specific aspect of this text, or if you have other questions about machine learning!\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "!python multiprompt_summarizer.py -f /content/book.txt --model gemma2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uCR-LTuASXrn",
        "outputId": "95bf2e67-0d45-41fb-b5be-619a305879ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generating summaries using different approaches...\n",
            "\n",
            "Generating TLDR Style summary...\n",
            "\n",
            "Generating Structured Analysis summary...\n",
            "\n",
            "Generating Concise 5-Point summary...\n",
            "\n",
            "Generating Comprehensive TLDR summary...\n",
            "\n",
            "================================================================================\n",
            "SUMMARY RESULTS\n",
            "================================================================================\n",
            "\n",
            "TLDR Style\n",
            "----------\n",
            "## TLDR: Samsung Microwave Not Heating?\n",
            "\n",
            "* **Check Power:** Make sure it's plugged in properly and the cord isn't damaged.\n",
            "* **Inspect Door Seal:**  Ensure the door is fully closed and the seals are clean.\n",
            "* **Test Function:** Heat a cup of water for 1-2 minutes on high power. If it doesn't heat, there could be an internal issue.\n",
            "* **Restart Microwave:** Unplug for 30 seconds, then plug back in.\n",
            "* **Contact Samsung:** If nothing works, call Samsung support with your model and serial number.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Structured Analysis\n",
            "-------------------\n",
            "Here's a breakdown of the text into bullet points:\n",
            "\n",
            "**Problem/Issue Addressed:**\n",
            "\n",
            "*  The document addresses issues with Samsung microwave ovens that are not heating properly.\n",
            "\n",
            "**Key Steps/Solutions:**\n",
            "\n",
            "* **Inspect Power Supply:** \n",
            "    * Verify the microwave is plugged into a working power outlet.\n",
            "    * Examine the power cord for any visible damage.\n",
            "* **Check Door Seal:**\n",
            "    * Make sure the microwave door is completely closed.\n",
            "    * Ensure the door seals are clean and undamaged.\n",
            "* **Test Cooking Mode:**\n",
            "    * Place a cup of water inside the microwave.\n",
            "    * Run it on high power for 1-2 minutes. If the water doesn't heat, there could be a problem with the magnetron or internal components.\n",
            "* **Reset Microwave:**\n",
            "    * Unplug the microwave for 30 seconds.\n",
            "    * Plug it back in and restart it.\n",
            "\n",
            "* **Contact Samsung Service:** If none of the above steps resolve the issue, reach out to Samsung Support with your microwave's model and serial number.\n",
            "\n",
            "\n",
            "**Important Notes/Cautions:**\n",
            "\n",
            "*  There are no explicit cautions mentioned in the text besides contacting Samsung service for persistent issues. \n",
            "* It's generally important to exercise caution when dealing with electrical appliances. If you are uncomfortable performing any of these steps, it's best to seek professional assistance.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Concise 5-Point\n",
            "---------------\n",
            "Here are the essential troubleshooting steps for a Samsung microwave that's not heating:\n",
            "\n",
            "* **Check Power:** Make sure the microwave is plugged into a working outlet and the power cord isn't damaged.\n",
            "* **Inspect Door Seal:** Ensure the door is fully closed and the seals are clean and undamaged. A faulty seal can prevent heating.\n",
            "* **Test Heating:**  Place water in the microwave and run it on high for 1-2 minutes. If it doesn't heat, there might be an issue with internal components.\n",
            "* **Reset Microwave:** Unplug the unit for 30 seconds, then plug it back in and try again. This can sometimes resolve minor software glitches.\n",
            "* **Contact Samsung Support:**  If none of these steps work, reach out to Samsung with your microwave's model and serial number for further assistance.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Comprehensive TLDR\n",
            "------------------\n",
            "##  Samsung Microwave Not Heating? Here's How to Fix It\n",
            "\n",
            "This guide provides a step-by-step approach to troubleshoot heating issues in your Samsung microwave oven. \n",
            "\n",
            "\n",
            "**1. Check the Power Supply:**\n",
            "\n",
            "* **Plug it In:** Make sure the microwave is securely plugged into a functioning wall outlet.\n",
            "* **Inspect the Cord:** Examine the power cord for any visible damage, such as fraying or cuts.  \n",
            "\n",
            "**2. Verify the Door Seal:**\n",
            "\n",
            "* **Closed and Secure:** Ensure the microwave door is fully closed and latched properly.\n",
            "* **Clean Seals:** Inspect the door seals for any dirt, food debris, or damage that could prevent a tight seal.\n",
            "\n",
            "**3. Test Heating Function:**\n",
            "\n",
            "* **Water Test:** Place a cup of water inside the microwave and run it on high power for 1-2 minutes. If the water doesn't heat, there might be an issue with the magnetron (heating element) or other internal components.\n",
            "\n",
            "**4. Reset the Microwave:**\n",
            "\n",
            "* **Power Cycle:** Unplug the microwave from the outlet for 30 seconds, then plug it back in and restart. This can often resolve minor software glitches.\n",
            "\n",
            "\n",
            "**5. Contact Samsung Support (If Necessary):**\n",
            "\n",
            "* If none of the above steps resolve the heating issue, reach out to Samsung Support directly.\n",
            "* Have your microwave's model and serial number readily available when contacting them.  They can provide further assistance or arrange for a repair if needed.\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "!python multiprompt_summarizer.py -f /content/samsung_microwave_support.txt --model gemma2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y91Nnz55SZHB",
        "outputId": "69187da6-c036-4722-889d-23ab16740bab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generating summaries using different approaches...\n",
            "\n",
            "Generating TLDR Style summary...\n",
            "\n",
            "Generating Structured Analysis summary...\n",
            "\n",
            "Generating Concise 5-Point summary...\n",
            "\n",
            "Generating Comprehensive TLDR summary...\n",
            "\n",
            "================================================================================\n",
            "SUMMARY RESULTS\n",
            "================================================================================\n",
            "\n",
            "TLDR Style\n",
            "----------\n",
            "## TLDR; Samsung Fridge Not Cooling?\n",
            "\n",
            "* **Check Temperature:** Is it set to 3¬∞C for fridge and -18¬∞C for freezer?\n",
            "* **Inspect Seals:** Are door seals clean & undamaged? Replace if necessary.\n",
            "* **Clear Ventilation:**  Ensure air vents inside the fridge are not blocked.\n",
            "* **Clean Coils:** Vacuum or brush the condenser coils (back/bottom).\n",
            "* **Power Cycle:** Unplug for 5 minutes, then plug back in.\n",
            "\n",
            "**Still not cooling? Contact Samsung Support or schedule a repair.**\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Structured Analysis\n",
            "-------------------\n",
            "Here's a breakdown of the troubleshooting guide:\n",
            "\n",
            "**Problem/Issue Addressed:**  Samsung refrigerator is not cooling properly.\n",
            "\n",
            "**Key Steps/Solutions:**\n",
            "\n",
            "* **Check Temperature Settings:** Verify fridge and freezer are set to 3¬∞C and -18¬∞C respectively.\n",
            "* **Inspect Door Seals:** Ensure seals are clean, undamaged, and create a tight seal. Replace if necessary.\n",
            "* **Clear Ventilation:** Remove any food obstructing air vents inside the refrigerator.\n",
            "* **Clean Coils:** Use a vacuum or brush to clean condenser coils located at the back or bottom of the fridge.\n",
            "* **Power Cycle:** Unplug the refrigerator for 5 minutes, then plug it back in to reset the cooling system.\n",
            "\n",
            "**Important Notes/Cautions:**\n",
            "\n",
            "* If the problem continues after trying these steps, contact Samsung Support or schedule a repair through their service app. \n",
            "\n",
            "\n",
            "Let me know if you have any other questions.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Concise 5-Point\n",
            "---------------\n",
            "Here's a 5-bullet point summary of the provided text:\n",
            "\n",
            "* **Check Temperature Settings:** Ensure fridge and freezer temperatures are set to the recommended 3¬∞C and -18¬∞C respectively.\n",
            "* **Inspect Door Seals:** Clean and replace damaged door seals to maintain proper temperature retention.\n",
            "* **Clear Ventilation:** Remove any food obstructions from air vents inside the refrigerator to allow for proper airflow.\n",
            "* **Clean Coils:** Vacuum or brush the condenser coils (located at the back or bottom) to remove dust and debris.\n",
            "* **Power Cycle:** Unplug the refrigerator for 5 minutes, then plug it back in to reset the cooling system.\n",
            "\n",
            "\n",
            "Let me know if you have any other text you'd like summarized!\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Comprehensive TLDR\n",
            "------------------\n",
            "## Troubleshooting Cooling Issues in Samsung Refrigerators: A Summary\n",
            "\n",
            "This guide provides actionable steps to resolve cooling problems in your Samsung refrigerator. \n",
            "\n",
            "**1. Basic Checks:**\n",
            "\n",
            "* **Temperature Settings:** Verify the fridge is set to 3¬∞C and the freezer to -18¬∞C. Incorrect settings can lead to inadequate cooling.\n",
            "* **Door Seals:** Inspect the seals for cleanliness and damage. A faulty seal allows cold air to escape, impacting temperature. Replace damaged seals promptly.\n",
            "\n",
            "**2. Maintaining Airflow:**\n",
            "\n",
            "* **Clear Ventilation:** Ensure food items are not obstructing the internal air vents.  Proper airflow is essential for consistent cooling.\n",
            "\n",
            "**3. Cleaning & Resetting:**\n",
            "\n",
            "* **Clean Coils:** Regularly clean the condenser coils located at the back or bottom of the fridge using a vacuum or brush. Dust buildup hinders efficient heat dissipation.\n",
            "* **Power Cycle:** Unplug the refrigerator for 5 minutes, then plug it back in. This can reset the cooling system and resolve minor glitches.\n",
            "\n",
            "**4. Seeking Professional Help:**\n",
            "\n",
            "* **Contact Service:** If the issue persists after attempting these steps, contact Samsung Support or schedule a repair through the Samsung Service app. A technician can diagnose and fix any complex problems. \n",
            "\n",
            "\n",
            "By following these steps, you can effectively troubleshoot common cooling issues in your Samsung refrigerator and ensure optimal performance. Remember to prioritize safety when handling electrical appliances.\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "!python multiprompt_summarizer.py -f /content/samsung_refrigerator_support.txt --model gemma2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6whyYf0gSaeM",
        "outputId": "2c90aa2b-59f7-415c-c842-e479fe339bfd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Generating summaries using different approaches...\n",
            "\n",
            "Generating TLDR Style summary...\n",
            "\n",
            "Generating Structured Analysis summary...\n",
            "\n",
            "Generating Concise 5-Point summary...\n",
            "\n",
            "Generating Comprehensive TLDR summary...\n",
            "\n",
            "================================================================================\n",
            "SUMMARY RESULTS\n",
            "================================================================================\n",
            "\n",
            "TLDR Style\n",
            "----------\n",
            "## TLDR; Samsung Smart TV Connectivity Problems?\n",
            "\n",
            "* **Check Network:** Make sure your router is working and other devices can connect. \n",
            "* **Restart Everything:** Power cycle both your TV and router.\n",
            "* **Update Software:** Go to Settings > Support > Software Update and select \"Update Now.\"\n",
            "* **Factory Reset (Last Resort):**  Settings > General > Reset (PIN: 0000). Be warned, this erases all data!\n",
            "* **Contact Samsung:** If nothing works, reach out with your TV model and a detailed problem description.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Structured Analysis\n",
            "-------------------\n",
            "Here's a breakdown of the text into bullet points:\n",
            "\n",
            "**Problem/Issue Addressed:**  Connectivity problems with Samsung Smart TVs, preventing streaming, browsing, or other smart functions.\n",
            "\n",
            "**Key Steps/Solutions:**\n",
            "\n",
            "* **Check Network Settings:** Verify your Wi-Fi router is working and that other devices can connect to the same network.\n",
            "* **Restart TV and Router:** Power cycle both your TV and router by unplugging them for a short period (30 seconds) and then plugging them back in.\n",
            "* **Update Software:** Ensure your TV's firmware is up-to-date through the Settings > Support > Software Update menu.\n",
            "* **Factory Reset (as a last resort):** If other steps fail, reset your TV to factory settings from Settings > General > Reset (default PIN: 0000).\n",
            "\n",
            "**Important Notes/Cautions:**\n",
            "\n",
            "*  A factory reset will erase all your TV's settings and data, so it should be used only as a last resort.\n",
            "*  If the problem persists after trying these steps, contact Samsung Support for further assistance. Provide your TV model number and a clear description of the issue.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Concise 5-Point\n",
            "---------------\n",
            "Here is a 5-bullet-point summary of the provided text:\n",
            "\n",
            "* **Verify Network Status:**  Confirm your Wi-Fi router is working correctly and other devices can connect to it. Check network settings on your Samsung Smart TV.\n",
            "* **Restart Devices:** Power cycle both your TV and router by unplugging them for 30 seconds, then plugging them back in. Reconnect the TV to Wi-Fi after restarting.\n",
            "* **Update Software:** Ensure your TV's firmware is up-to-date through the Settings > Support > Software Update menu. Select \"Update Now.\"\n",
            "* **Factory Reset (Last Resort):** If problems persist, consider resetting your TV to factory settings via Settings > General > Reset (default PIN: 0000).  \n",
            "* **Contact Samsung Support:** For unresolved issues, reach out to Samsung support with your TV model number and a detailed description of the problem.\n",
            "\n",
            "================================================================================\n",
            "\n",
            "Comprehensive TLDR\n",
            "------------------\n",
            "## Troubleshooting Connectivity Issues for Samsung Smart TVs\n",
            "\n",
            "This guide provides step-by-step instructions to resolve connectivity problems on your Samsung Smart TV. \n",
            "\n",
            "**1. Check Network Settings:**\n",
            "\n",
            "* **Access Network Status:** Navigate to \"Settings > General > Network > Network Status.\"\n",
            "* **Verify Router Functioning:** Ensure your Wi-Fi router is working correctly.\n",
            "* **Test Other Devices:**  Check if other devices can connect to the same network.\n",
            "\n",
            "**2. Restart TV and Router:**\n",
            "\n",
            "* **Power Off Both:** Turn off your TV and unplug it from the power source. Do the same for your router.\n",
            "* **Wait and Reconnect:**  Allow both devices to rest for 30 seconds. Then, plug them back in and reconnect your TV to Wi-Fi.\n",
            "\n",
            "**3. Update Software:**\n",
            "\n",
            "* **Check for Updates:** Go to \"Settings > Support > Software Update\" and select \"Update Now.\" This ensures your TV has the latest firmware.\n",
            "\n",
            "**4. Factory Reset (Last Resort):**\n",
            "\n",
            "* **Reset Settings:** If other steps fail, perform a factory reset: \"Settings > General > Reset\" (PIN: 0000 by default). *Note:* This will erase all personal data on your TV.\n",
            "\n",
            "**5. Contact Support:**\n",
            "\n",
            "If the problem persists after trying these solutions, contact Samsung Support with:\n",
            "* **TV Model Number:**\n",
            "* **Detailed Description of the Issue:**\n",
            "\n",
            "\n",
            "By following these steps, you can effectively troubleshoot and resolve most connectivity issues on your Samsung Smart TV.\n",
            "\n",
            "================================================================================\n"
          ]
        }
      ],
      "source": [
        "!python multiprompt_summarizer.py -f /content/samsung_tv_support.txt --model gemma2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xItX-6waNjcN"
      },
      "outputs": [],
      "source": [
        "!curl http://localhost:11434/api/tags"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qGUfJ3UwSFDM"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}